{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3adf4a2",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.externals.six import StringIO\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, PrecisionRecallDisplay,precision_recall_curve, plot_roc_curve, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import CategoricalNB,GaussianNB\n",
    "\n",
    "import scikitplot as skplt\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5cdf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, tree, linear_model, svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83dbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee850b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaea63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from skopt import BayesSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6930c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfcf50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/2022-Spring/PDA/Project/train.csv',index_col=0)\n",
    "test = pd.read_csv('D:/2022-Spring/PDA/Project/test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split fake data from real data and get the real data's indices (reference: https://www.kaggle.com/code/yag320/list-of-fake-samples-and-public-private-lb-split/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb128f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = test.values\n",
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(test_values)\n",
    "for feature in tqdm(range(test_values.shape[1])):\n",
    "    _, index_, count_ = np.unique(test_values[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index_[count_ == 1], feature] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Samples which have unique values are real the others are fake\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "print(len(real_samples_indexes))\n",
    "print(len(synthetic_samples_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ed694",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_samples_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in range(200): d['var_'+str(i)] = 'float32'\n",
    "d['target'] = 'uint8'\n",
    "d['ID_code'] = 'object'\n",
    "\n",
    "train = pd.read_csv('D:/2022-Spring/PDA/Project/train.csv', dtype=d)\n",
    "test = pd.read_csv('D:/2022-Spring/PDA/Project/test.csv', dtype=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add frequency encodes for 200 independent features\n",
    "def encode_FE(df,col,test):\n",
    "    cv = df[col].value_counts()\n",
    "    nm = col+'_FE'\n",
    "    df[nm] = df[col].map(cv)\n",
    "    test[nm] = test[col].map(cv)\n",
    "    test[nm].fillna(0,inplace=True)\n",
    "    if cv.max()<=255:\n",
    "        df[nm] = df[nm].astype('uint8')\n",
    "        test[nm] = test[nm].astype('uint8')\n",
    "    else:\n",
    "        df[nm] = df[nm].astype('uint16')\n",
    "        test[nm] = test[nm].astype('uint16')        \n",
    "    return\n",
    "\n",
    "test['target'] = -1\n",
    "comb = pd.concat([train,test.loc[real_samples_indexes]],axis=0,sort=True)\n",
    "for i in range(200): \n",
    "    encode_FE(comb,'var_'+str(i),test)\n",
    "train = comb[:len(train)]; del comb\n",
    "print('Added 200 new magic features!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21df890",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb2f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.iloc[:,2:]\n",
    "y=train.iloc[:,1]\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('ID_code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['target'] == 0]['target'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalance rate\n",
    "(200000-179902)/179902"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287dd83d",
   "metadata": {},
   "source": [
    "# 200 models + stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2466855d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_0',\n",
       " 'var_1',\n",
       " 'var_2',\n",
       " 'var_3',\n",
       " 'var_4',\n",
       " 'var_5',\n",
       " 'var_6',\n",
       " 'var_7',\n",
       " 'var_8',\n",
       " 'var_9',\n",
       " 'var_10',\n",
       " 'var_11',\n",
       " 'var_12',\n",
       " 'var_13',\n",
       " 'var_14',\n",
       " 'var_15',\n",
       " 'var_16',\n",
       " 'var_17',\n",
       " 'var_18',\n",
       " 'var_19',\n",
       " 'var_20',\n",
       " 'var_21',\n",
       " 'var_22',\n",
       " 'var_23',\n",
       " 'var_24',\n",
       " 'var_25',\n",
       " 'var_26',\n",
       " 'var_27',\n",
       " 'var_28',\n",
       " 'var_29',\n",
       " 'var_30',\n",
       " 'var_31',\n",
       " 'var_32',\n",
       " 'var_33',\n",
       " 'var_34',\n",
       " 'var_35',\n",
       " 'var_36',\n",
       " 'var_37',\n",
       " 'var_38',\n",
       " 'var_39',\n",
       " 'var_40',\n",
       " 'var_41',\n",
       " 'var_42',\n",
       " 'var_43',\n",
       " 'var_44',\n",
       " 'var_45',\n",
       " 'var_46',\n",
       " 'var_47',\n",
       " 'var_48',\n",
       " 'var_49',\n",
       " 'var_50',\n",
       " 'var_51',\n",
       " 'var_52',\n",
       " 'var_53',\n",
       " 'var_54',\n",
       " 'var_55',\n",
       " 'var_56',\n",
       " 'var_57',\n",
       " 'var_58',\n",
       " 'var_59',\n",
       " 'var_60',\n",
       " 'var_61',\n",
       " 'var_62',\n",
       " 'var_63',\n",
       " 'var_64',\n",
       " 'var_65',\n",
       " 'var_66',\n",
       " 'var_67',\n",
       " 'var_68',\n",
       " 'var_69',\n",
       " 'var_70',\n",
       " 'var_71',\n",
       " 'var_72',\n",
       " 'var_73',\n",
       " 'var_74',\n",
       " 'var_75',\n",
       " 'var_76',\n",
       " 'var_77',\n",
       " 'var_78',\n",
       " 'var_79',\n",
       " 'var_80',\n",
       " 'var_81',\n",
       " 'var_82',\n",
       " 'var_83',\n",
       " 'var_84',\n",
       " 'var_85',\n",
       " 'var_86',\n",
       " 'var_87',\n",
       " 'var_88',\n",
       " 'var_89',\n",
       " 'var_90',\n",
       " 'var_91',\n",
       " 'var_92',\n",
       " 'var_93',\n",
       " 'var_94',\n",
       " 'var_95',\n",
       " 'var_96',\n",
       " 'var_97',\n",
       " 'var_98',\n",
       " 'var_99',\n",
       " 'var_100',\n",
       " 'var_101',\n",
       " 'var_102',\n",
       " 'var_103',\n",
       " 'var_104',\n",
       " 'var_105',\n",
       " 'var_106',\n",
       " 'var_107',\n",
       " 'var_108',\n",
       " 'var_109',\n",
       " 'var_110',\n",
       " 'var_111',\n",
       " 'var_112',\n",
       " 'var_113',\n",
       " 'var_114',\n",
       " 'var_115',\n",
       " 'var_116',\n",
       " 'var_117',\n",
       " 'var_118',\n",
       " 'var_119',\n",
       " 'var_120',\n",
       " 'var_121',\n",
       " 'var_122',\n",
       " 'var_123',\n",
       " 'var_124',\n",
       " 'var_125',\n",
       " 'var_126',\n",
       " 'var_127',\n",
       " 'var_128',\n",
       " 'var_129',\n",
       " 'var_130',\n",
       " 'var_131',\n",
       " 'var_132',\n",
       " 'var_133',\n",
       " 'var_134',\n",
       " 'var_135',\n",
       " 'var_136',\n",
       " 'var_137',\n",
       " 'var_138',\n",
       " 'var_139',\n",
       " 'var_140',\n",
       " 'var_141',\n",
       " 'var_142',\n",
       " 'var_143',\n",
       " 'var_144',\n",
       " 'var_145',\n",
       " 'var_146',\n",
       " 'var_147',\n",
       " 'var_148',\n",
       " 'var_149',\n",
       " 'var_150',\n",
       " 'var_151',\n",
       " 'var_152',\n",
       " 'var_153',\n",
       " 'var_154',\n",
       " 'var_155',\n",
       " 'var_156',\n",
       " 'var_157',\n",
       " 'var_158',\n",
       " 'var_159',\n",
       " 'var_160',\n",
       " 'var_161',\n",
       " 'var_162',\n",
       " 'var_163',\n",
       " 'var_164',\n",
       " 'var_165',\n",
       " 'var_166',\n",
       " 'var_167',\n",
       " 'var_168',\n",
       " 'var_169',\n",
       " 'var_170',\n",
       " 'var_171',\n",
       " 'var_172',\n",
       " 'var_173',\n",
       " 'var_174',\n",
       " 'var_175',\n",
       " 'var_176',\n",
       " 'var_177',\n",
       " 'var_178',\n",
       " 'var_179',\n",
       " 'var_180',\n",
       " 'var_181',\n",
       " 'var_182',\n",
       " 'var_183',\n",
       " 'var_184',\n",
       " 'var_185',\n",
       " 'var_186',\n",
       " 'var_187',\n",
       " 'var_188',\n",
       " 'var_189',\n",
       " 'var_190',\n",
       " 'var_191',\n",
       " 'var_192',\n",
       " 'var_193',\n",
       " 'var_194',\n",
       " 'var_195',\n",
       " 'var_196',\n",
       " 'var_197',\n",
       " 'var_198',\n",
       " 'var_199']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "144c9c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_0\n",
      "var_1\n",
      "var_2\n",
      "var_3\n",
      "var_4\n",
      "var_5\n",
      "var_6\n",
      "var_7\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-d7cddd1de364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m                            \u001b[0mpassthrough\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Train final model on predictions and base data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                            verbose=1)\n\u001b[1;32m---> 22\u001b[1;33m     model = stack.fit(np.hstack([X_train[var].values.reshape(-1, 1),\n\u001b[0m\u001b[0;32m     23\u001b[0m                       X_train[var_count_name].values.reshape(-1, 1)]), y_train.values)\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"final_estimator_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[1;34m\"sample_weight\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         )\n\u001b[1;32m--> 193\u001b[1;33m         predictions = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m    194\u001b[0m             delayed(cross_val_predict)(\n\u001b[0;32m    195\u001b[0m                 \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "y_pred_200 = 0\n",
    "for var in features:\n",
    "    print(var)\n",
    "    \n",
    "    model_1 = CatBoostClassifier(scale_pos_weight=1/11)\n",
    "    model_2 = XGBClassifier(scale_pos_weight=1/11)\n",
    "    model_4 = LGBMClassifier(scale_pos_weight=1/11)\n",
    "    \n",
    "    var_count_name = var + '_FE'\n",
    "    all_models = [('xgb', model_2), ('lgbm', model_4)]\n",
    "\n",
    "     # create meta model\n",
    "    final_lr = LogisticRegression(class_weight='balanced', solver='saga')\n",
    "\n",
    "    # stacked model\n",
    "    stack = StackingClassifier(estimators=all_models,\n",
    "                           final_estimator=final_lr,\n",
    "                           cv=None,\n",
    "                           stack_method='predict_proba',\n",
    "                           n_jobs=-1,\n",
    "                           passthrough=True, # Train final model on predictions and base data\n",
    "                           verbose=1)\n",
    "    model = stack.fit(np.hstack([X_train[var].values.reshape(-1, 1),\n",
    "                      X_train[var_count_name].values.reshape(-1, 1)]), y_train.values)\n",
    "    \n",
    "    y_pred_200 += model.predict_proba(np.hstack([X_test[var].values.reshape(-1, 1),\n",
    "                  X_test[var_count_name].values.reshape(-1, 1)]))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe3f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_200 = pd.DataFrame({\"ID_code\": test.iloc[:,0]})\n",
    "submission_200[\"target\"] = y_pred_200/200\n",
    "submission_200.to_csv(\"submission_200.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbf0cd",
   "metadata": {},
   "source": [
    "## LGBM 0.891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "845a6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier(**{\n",
    "     'learning_rate': 0.04,\n",
    "     'num_leaves': 31,\n",
    "     'max_bin': 1023,\n",
    "     'min_child_samples': 1000,\n",
    "     'reg_alpha': 0.1,\n",
    "     'reg_lambda': 0.2,\n",
    "     'feature_fraction': 1.0,\n",
    "     'bagging_freq': 1,\n",
    "     'bagging_fraction': 0.85,\n",
    "     'objective': 'binary',\n",
    "     'n_jobs': -1,\n",
    "     'n_estimators':400,\n",
    "     'class_weight':{0:1, 1:0.1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "72903085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.85, bagging_freq=1,\n",
       "               class_weight={0: 1, 1: 0.1}, feature_fraction=1.0,\n",
       "               learning_rate=0.04, max_bin=1023, min_child_samples=1000,\n",
       "               n_estimators=400, objective='binary', reg_alpha=0.1,\n",
       "               reg_lambda=0.2)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model.fit(X_train,y_train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b24cfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgbm = lgbm_model.predict_proba(test[features])[:,1] \n",
    "submission_lgbm = pd.DataFrame({\"ID_code\": test.iloc[:,0]})\n",
    "submission_lgbm[\"target\"] = y_pred_lgbm\n",
    "submission_lgbm.to_csv(\"submission_lgbm.csv\", index=False)\n",
    "# score: 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "aa107ab0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yujun Wang\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "response method decision_function or predict_proba is not defined in StackingClassifier",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-319-299cb334cc5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py\u001b[0m in \u001b[0;36mplot_roc_curve\u001b[1;34m(estimator, X, y, sample_weight, drop_intermediate, response_method, name, ax, pos_label, **kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[0mcheck_matplotlib_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"plot_roc_curve\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m     y_pred, pos_label = _get_response(\n\u001b[0m\u001b[0;32m    452\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\base.py\u001b[0m in \u001b[0;36m_get_response\u001b[1;34m(X, estimator, response_method, pos_label)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mprediction_method\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_classifier_response_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\base.py\u001b[0m in \u001b[0;36m_check_classifier_response_method\u001b[1;34m(estimator, response_method)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mprediction_method\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_proba\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprediction_method\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     42\u001b[0m                 error_msg.format(\n\u001b[0;32m     43\u001b[0m                     \u001b[1;34m\"decision_function or predict_proba\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: response method decision_function or predict_proba is not defined in StackingClassifier"
     ]
    }
   ],
   "source": [
    "roc = plot_roc_curve(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b827ab",
   "metadata": {},
   "source": [
    "## CNN 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "34b50034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_FE</th>\n",
       "      <th>var_191_FE</th>\n",
       "      <th>var_192_FE</th>\n",
       "      <th>var_193_FE</th>\n",
       "      <th>var_194_FE</th>\n",
       "      <th>var_195_FE</th>\n",
       "      <th>var_196_FE</th>\n",
       "      <th>var_197_FE</th>\n",
       "      <th>var_198_FE</th>\n",
       "      <th>var_199_FE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>2.9252</td>\n",
       "      <td>9.476300</td>\n",
       "      <td>13.310200</td>\n",
       "      <td>26.537600</td>\n",
       "      <td>1.4403</td>\n",
       "      <td>14.7100</td>\n",
       "      <td>6.0454</td>\n",
       "      <td>9.5426</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>-0.4032</td>\n",
       "      <td>-13.695000</td>\n",
       "      <td>8.406800</td>\n",
       "      <td>35.473400</td>\n",
       "      <td>1.7093</td>\n",
       "      <td>15.1866</td>\n",
       "      <td>2.6227</td>\n",
       "      <td>7.3412</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>-0.3249</td>\n",
       "      <td>-0.393900</td>\n",
       "      <td>12.631700</td>\n",
       "      <td>14.886300</td>\n",
       "      <td>1.3854</td>\n",
       "      <td>15.0284</td>\n",
       "      <td>3.9995</td>\n",
       "      <td>5.3683</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>2.3061</td>\n",
       "      <td>-19.859200</td>\n",
       "      <td>22.531601</td>\n",
       "      <td>18.612900</td>\n",
       "      <td>1.3512</td>\n",
       "      <td>9.3291</td>\n",
       "      <td>4.2835</td>\n",
       "      <td>10.3907</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>-9.4458</td>\n",
       "      <td>-22.926399</td>\n",
       "      <td>12.356200</td>\n",
       "      <td>17.341000</td>\n",
       "      <td>1.6940</td>\n",
       "      <td>7.1179</td>\n",
       "      <td>5.1934</td>\n",
       "      <td>8.8230</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>3.7574</td>\n",
       "      <td>-18.847300</td>\n",
       "      <td>9.935800</td>\n",
       "      <td>25.335899</td>\n",
       "      <td>1.3647</td>\n",
       "      <td>11.8509</td>\n",
       "      <td>5.0357</td>\n",
       "      <td>6.4630</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>6.5576</td>\n",
       "      <td>-15.529400</td>\n",
       "      <td>9.550100</td>\n",
       "      <td>11.854800</td>\n",
       "      <td>1.5127</td>\n",
       "      <td>11.3998</td>\n",
       "      <td>4.2304</td>\n",
       "      <td>6.6777</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>4.4004</td>\n",
       "      <td>-8.057400</td>\n",
       "      <td>10.060600</td>\n",
       "      <td>25.253500</td>\n",
       "      <td>1.8019</td>\n",
       "      <td>10.4973</td>\n",
       "      <td>4.2183</td>\n",
       "      <td>9.1158</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>1.4245</td>\n",
       "      <td>-2.389100</td>\n",
       "      <td>24.662600</td>\n",
       "      <td>19.778299</td>\n",
       "      <td>1.5780</td>\n",
       "      <td>14.3962</td>\n",
       "      <td>4.8206</td>\n",
       "      <td>12.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>-7.3826</td>\n",
       "      <td>0.963600</td>\n",
       "      <td>13.496600</td>\n",
       "      <td>31.362900</td>\n",
       "      <td>1.5517</td>\n",
       "      <td>12.1898</td>\n",
       "      <td>3.5216</td>\n",
       "      <td>6.8915</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1  var_10    var_100    var_101    var_102  var_103  \\\n",
       "0        8.9255 -6.7863  2.9252   9.476300  13.310200  26.537600   1.4403   \n",
       "1       11.5006 -4.1473 -0.4032 -13.695000   8.406800  35.473400   1.7093   \n",
       "2        8.6093 -2.7457 -0.3249  -0.393900  12.631700  14.886300   1.3854   \n",
       "3       11.0604 -2.1518  2.3061 -19.859200  22.531601  18.612900   1.3512   \n",
       "4        9.8369 -1.4834 -9.4458 -22.926399  12.356200  17.341000   1.6940   \n",
       "...         ...     ...     ...        ...        ...        ...      ...   \n",
       "199995  11.4880 -0.4956  3.7574 -18.847300   9.935800  25.335899   1.3647   \n",
       "199996   4.9149 -2.4484  6.5576 -15.529400   9.550100  11.854800   1.5127   \n",
       "199997  11.2232 -5.0518  4.4004  -8.057400  10.060600  25.253500   1.8019   \n",
       "199998   9.7148 -8.6098  1.4245  -2.389100  24.662600  19.778299   1.5780   \n",
       "199999  10.8762 -5.7105 -7.3826   0.963600  13.496600  31.362900   1.5517   \n",
       "\n",
       "        var_104  var_105  var_106  ...  var_190_FE  var_191_FE  var_192_FE  \\\n",
       "0       14.7100   6.0454   9.5426  ...           3           8           9   \n",
       "1       15.1866   2.6227   7.3412  ...           8           5           9   \n",
       "2       15.0284   3.9995   5.3683  ...           4           5           6   \n",
       "3        9.3291   4.2835  10.3907  ...           2           3           6   \n",
       "4        7.1179   5.1934   8.8230  ...           3           8           1   \n",
       "...         ...      ...      ...  ...         ...         ...         ...   \n",
       "199995  11.8509   5.0357   6.4630  ...           4           1           5   \n",
       "199996  11.3998   4.2304   6.6777  ...           2           3           8   \n",
       "199997  10.4973   4.2183   9.1158  ...           3           4           5   \n",
       "199998  14.3962   4.8206  12.2354  ...           6           6           3   \n",
       "199999  12.1898   3.5216   6.8915  ...           5           3           3   \n",
       "\n",
       "        var_193_FE  var_194_FE  var_195_FE  var_196_FE  var_197_FE  \\\n",
       "0                4           9           5           5          14   \n",
       "1                2           4           4           4          21   \n",
       "2                2           2           2           3          12   \n",
       "3                4           4           8           5           4   \n",
       "4                1           1           9           5           9   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "199995           5           3           7           1          16   \n",
       "199996           1           2           6           4           4   \n",
       "199997           3           2           7           4          17   \n",
       "199998           2           7           7           2           7   \n",
       "199999           2           4           3           3           9   \n",
       "\n",
       "        var_198_FE  var_199_FE  \n",
       "0                5           2  \n",
       "1                6           2  \n",
       "2                4           2  \n",
       "3                2           2  \n",
       "4                2           2  \n",
       "...            ...         ...  \n",
       "199995           4           2  \n",
       "199996           7           2  \n",
       "199997           4           1  \n",
       "199998           6           1  \n",
       "199999           3           1  \n",
       "\n",
       "[200000 rows x 400 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "95b634fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3e4b9668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195896    1\n",
       "47114     0\n",
       "144875    0\n",
       "184791    0\n",
       "123269    0\n",
       "         ..\n",
       "194442    1\n",
       "65615     0\n",
       "77655     0\n",
       "56088     0\n",
       "38408     0\n",
       "Name: target, Length: 140000, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "306f224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1], 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "759033d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_21 (Conv1D)          (None, 200, 400)          1200      \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 80000)             0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 80001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,201\n",
      "Trainable params: 81,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N_units = 400\n",
    "kernel_size=2\n",
    "strides=2\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(N_units, kernel_size=kernel_size, strides=strides, padding='valid', \n",
    "                     activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "cb24e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4375/4375 - 86s - loss: 0.2971 - accuracy: 0.9028 - val_loss: 0.2555 - val_accuracy: 0.9089 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 2/10\n",
      "4375/4375 - 92s - loss: 0.2502 - accuracy: 0.9090 - val_loss: 0.2427 - val_accuracy: 0.9098 - lr: 0.0010 - 92s/epoch - 21ms/step\n",
      "Epoch 3/10\n",
      "4375/4375 - 86s - loss: 0.2403 - accuracy: 0.9124 - val_loss: 0.2573 - val_accuracy: 0.9053 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 4/10\n",
      "4375/4375 - 87s - loss: 0.2364 - accuracy: 0.9130 - val_loss: 0.2334 - val_accuracy: 0.9136 - lr: 0.0010 - 87s/epoch - 20ms/step\n",
      "Epoch 5/10\n",
      "4375/4375 - 89s - loss: 0.2324 - accuracy: 0.9147 - val_loss: 0.2305 - val_accuracy: 0.9152 - lr: 0.0010 - 89s/epoch - 20ms/step\n",
      "Epoch 6/10\n",
      "4375/4375 - 86s - loss: 0.2303 - accuracy: 0.9156 - val_loss: 0.2290 - val_accuracy: 0.9149 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 7/10\n",
      "4375/4375 - 85s - loss: 0.2289 - accuracy: 0.9151 - val_loss: 0.2249 - val_accuracy: 0.9162 - lr: 0.0010 - 85s/epoch - 20ms/step\n",
      "Epoch 8/10\n",
      "4375/4375 - 86s - loss: 0.2274 - accuracy: 0.9159 - val_loss: 0.2255 - val_accuracy: 0.9163 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 9/10\n",
      "4375/4375 - 86s - loss: 0.2267 - accuracy: 0.9164 - val_loss: 0.2273 - val_accuracy: 0.9159 - lr: 0.0010 - 86s/epoch - 20ms/step\n",
      "Epoch 10/10\n",
      "4375/4375 - 86s - loss: 0.2260 - accuracy: 0.9168 - val_loss: 0.2233 - val_accuracy: 0.9170 - lr: 0.0010 - 86s/epoch - 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c07e0c8e0>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "LR_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=2, factor=.5, min_lr=.0001)\n",
    "EarlyStop_callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True)\n",
    "my_callback=[EarlyStop_callback, LR_callback]\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train, y_train, \n",
    "              validation_data=(X_test, y_test),\n",
    "              epochs=epochs,\n",
    "              verbose=2,\n",
    "              callbacks = my_callback,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fb2354a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cnn = cnn_model.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "18502e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06314817],\n",
       "       [0.0754644 ],\n",
       "       [0.11738187],\n",
       "       ...,\n",
       "       [0.0029299 ],\n",
       "       [0.05230972],\n",
       "       [0.01667929]], dtype=float32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ca6eaec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cnn = pd.DataFrame({\"ID_code\": test.iloc[:,0]})\n",
    "submission_cnn[\"target\"] = y_pred_cnn\n",
    "submission_cnn.to_csv(\"submission_cnn.csv\", index=False)\n",
    "# score: 0.875"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b080be8",
   "metadata": {},
   "source": [
    "# XGBoost 0.895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a61b8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.5,\n",
    "              enable_categorical=False, eval_metric='auc', gamma=0, gpu_id=-1,\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=5000, n_jobs=4, num_parallel_tree=1,\n",
    "              predictor='auto', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "              scale_pos_weight=1, subsample=0.5, tree_method='exact',\n",
    "              validate_parameters=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "40c4ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with another parameter combination score:0.8934\n",
    "xgb_model = XGBClassifier(learning_rate=0.1,max_depth=5,scale_pos_weight=1/11,n_estimators=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "3fc34955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:48:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=400, n_jobs=16,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=0.09090909090909091,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "55854366",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_model.predict_proba(test[features])[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "62a31a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_xgb = pd.DataFrame({\"ID_code\": test.iloc[:,0]})\n",
    "submission_xgb[\"target\"] = y_pred_xgb\n",
    "submission_xgb.to_csv(\"submission_xgb.csv\", index=False)\n",
    "# 0.89527 LB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de931c04",
   "metadata": {},
   "source": [
    "# CatBoost 0.896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e52a044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.084983\n",
      "0:\tlearn: 0.5203676\ttotal: 101ms\tremaining: 1m 41s\n",
      "1:\tlearn: 0.3946951\ttotal: 179ms\tremaining: 1m 29s\n",
      "2:\tlearn: 0.3040008\ttotal: 283ms\tremaining: 1m 34s\n",
      "3:\tlearn: 0.2391217\ttotal: 362ms\tremaining: 1m 30s\n",
      "4:\tlearn: 0.1920484\ttotal: 459ms\tremaining: 1m 31s\n",
      "5:\tlearn: 0.1582466\ttotal: 545ms\tremaining: 1m 30s\n",
      "6:\tlearn: 0.1335917\ttotal: 618ms\tremaining: 1m 27s\n",
      "7:\tlearn: 0.1152838\ttotal: 708ms\tremaining: 1m 27s\n",
      "8:\tlearn: 0.1017257\ttotal: 786ms\tremaining: 1m 26s\n",
      "9:\tlearn: 0.0915863\ttotal: 858ms\tremaining: 1m 24s\n",
      "10:\tlearn: 0.0838948\ttotal: 910ms\tremaining: 1m 21s\n",
      "11:\tlearn: 0.0779929\ttotal: 975ms\tremaining: 1m 20s\n",
      "12:\tlearn: 0.0733627\ttotal: 1.05s\tremaining: 1m 20s\n",
      "13:\tlearn: 0.0698229\ttotal: 1.12s\tremaining: 1m 19s\n",
      "14:\tlearn: 0.0668983\ttotal: 1.19s\tremaining: 1m 18s\n",
      "15:\tlearn: 0.0646561\ttotal: 1.27s\tremaining: 1m 18s\n",
      "16:\tlearn: 0.0627405\ttotal: 1.36s\tremaining: 1m 18s\n",
      "17:\tlearn: 0.0611685\ttotal: 1.43s\tremaining: 1m 18s\n",
      "18:\tlearn: 0.0599582\ttotal: 1.5s\tremaining: 1m 17s\n",
      "19:\tlearn: 0.0589276\ttotal: 1.57s\tremaining: 1m 17s\n",
      "20:\tlearn: 0.0580059\ttotal: 1.64s\tremaining: 1m 16s\n",
      "21:\tlearn: 0.0572782\ttotal: 1.7s\tremaining: 1m 15s\n",
      "22:\tlearn: 0.0566284\ttotal: 1.77s\tremaining: 1m 15s\n",
      "23:\tlearn: 0.0561025\ttotal: 1.84s\tremaining: 1m 14s\n",
      "24:\tlearn: 0.0556445\ttotal: 1.9s\tremaining: 1m 14s\n",
      "25:\tlearn: 0.0552458\ttotal: 1.97s\tremaining: 1m 13s\n",
      "26:\tlearn: 0.0549087\ttotal: 2.04s\tremaining: 1m 13s\n",
      "27:\tlearn: 0.0546270\ttotal: 2.1s\tremaining: 1m 12s\n",
      "28:\tlearn: 0.0543953\ttotal: 2.16s\tremaining: 1m 12s\n",
      "29:\tlearn: 0.0541736\ttotal: 2.22s\tremaining: 1m 11s\n",
      "30:\tlearn: 0.0539479\ttotal: 2.29s\tremaining: 1m 11s\n",
      "31:\tlearn: 0.0537358\ttotal: 2.35s\tremaining: 1m 11s\n",
      "32:\tlearn: 0.0535492\ttotal: 2.43s\tremaining: 1m 11s\n",
      "33:\tlearn: 0.0533725\ttotal: 2.51s\tremaining: 1m 11s\n",
      "34:\tlearn: 0.0532071\ttotal: 2.57s\tremaining: 1m 10s\n",
      "35:\tlearn: 0.0530557\ttotal: 2.64s\tremaining: 1m 10s\n",
      "36:\tlearn: 0.0529186\ttotal: 2.7s\tremaining: 1m 10s\n",
      "37:\tlearn: 0.0527756\ttotal: 2.77s\tremaining: 1m 10s\n",
      "38:\tlearn: 0.0526504\ttotal: 2.85s\tremaining: 1m 10s\n",
      "39:\tlearn: 0.0525574\ttotal: 2.92s\tremaining: 1m 10s\n",
      "40:\tlearn: 0.0524494\ttotal: 2.98s\tremaining: 1m 9s\n",
      "41:\tlearn: 0.0523402\ttotal: 3.04s\tremaining: 1m 9s\n",
      "42:\tlearn: 0.0522438\ttotal: 3.1s\tremaining: 1m 9s\n",
      "43:\tlearn: 0.0521316\ttotal: 3.17s\tremaining: 1m 8s\n",
      "44:\tlearn: 0.0520273\ttotal: 3.26s\tremaining: 1m 9s\n",
      "45:\tlearn: 0.0519287\ttotal: 3.33s\tremaining: 1m 9s\n",
      "46:\tlearn: 0.0518385\ttotal: 3.4s\tremaining: 1m 9s\n",
      "47:\tlearn: 0.0517602\ttotal: 3.48s\tremaining: 1m 9s\n",
      "48:\tlearn: 0.0516699\ttotal: 3.55s\tremaining: 1m 8s\n",
      "49:\tlearn: 0.0515832\ttotal: 3.61s\tremaining: 1m 8s\n",
      "50:\tlearn: 0.0515050\ttotal: 3.67s\tremaining: 1m 8s\n",
      "51:\tlearn: 0.0514210\ttotal: 3.74s\tremaining: 1m 8s\n",
      "52:\tlearn: 0.0513331\ttotal: 3.8s\tremaining: 1m 7s\n",
      "53:\tlearn: 0.0512581\ttotal: 3.88s\tremaining: 1m 7s\n",
      "54:\tlearn: 0.0511712\ttotal: 3.94s\tremaining: 1m 7s\n",
      "55:\tlearn: 0.0510890\ttotal: 4.01s\tremaining: 1m 7s\n",
      "56:\tlearn: 0.0510101\ttotal: 4.07s\tremaining: 1m 7s\n",
      "57:\tlearn: 0.0509330\ttotal: 4.13s\tremaining: 1m 7s\n",
      "58:\tlearn: 0.0508410\ttotal: 4.19s\tremaining: 1m 6s\n",
      "59:\tlearn: 0.0507589\ttotal: 4.26s\tremaining: 1m 6s\n",
      "60:\tlearn: 0.0506713\ttotal: 4.33s\tremaining: 1m 6s\n",
      "61:\tlearn: 0.0505943\ttotal: 4.39s\tremaining: 1m 6s\n",
      "62:\tlearn: 0.0505216\ttotal: 4.45s\tremaining: 1m 6s\n",
      "63:\tlearn: 0.0504491\ttotal: 4.52s\tremaining: 1m 6s\n",
      "64:\tlearn: 0.0503836\ttotal: 4.59s\tremaining: 1m 6s\n",
      "65:\tlearn: 0.0503040\ttotal: 4.66s\tremaining: 1m 5s\n",
      "66:\tlearn: 0.0502334\ttotal: 4.71s\tremaining: 1m 5s\n",
      "67:\tlearn: 0.0501550\ttotal: 4.78s\tremaining: 1m 5s\n",
      "68:\tlearn: 0.0500827\ttotal: 4.84s\tremaining: 1m 5s\n",
      "69:\tlearn: 0.0500071\ttotal: 4.91s\tremaining: 1m 5s\n",
      "70:\tlearn: 0.0499299\ttotal: 4.96s\tremaining: 1m 4s\n",
      "71:\tlearn: 0.0498635\ttotal: 5.03s\tremaining: 1m 4s\n",
      "72:\tlearn: 0.0498066\ttotal: 5.1s\tremaining: 1m 4s\n",
      "73:\tlearn: 0.0497468\ttotal: 5.16s\tremaining: 1m 4s\n",
      "74:\tlearn: 0.0496738\ttotal: 5.22s\tremaining: 1m 4s\n",
      "75:\tlearn: 0.0496085\ttotal: 5.3s\tremaining: 1m 4s\n",
      "76:\tlearn: 0.0495417\ttotal: 5.36s\tremaining: 1m 4s\n",
      "77:\tlearn: 0.0494828\ttotal: 5.43s\tremaining: 1m 4s\n",
      "78:\tlearn: 0.0494338\ttotal: 5.5s\tremaining: 1m 4s\n",
      "79:\tlearn: 0.0493781\ttotal: 5.57s\tremaining: 1m 4s\n",
      "80:\tlearn: 0.0493183\ttotal: 5.63s\tremaining: 1m 3s\n",
      "81:\tlearn: 0.0492499\ttotal: 5.7s\tremaining: 1m 3s\n",
      "82:\tlearn: 0.0491876\ttotal: 5.76s\tremaining: 1m 3s\n",
      "83:\tlearn: 0.0491381\ttotal: 5.83s\tremaining: 1m 3s\n",
      "84:\tlearn: 0.0490714\ttotal: 5.89s\tremaining: 1m 3s\n",
      "85:\tlearn: 0.0490100\ttotal: 5.96s\tremaining: 1m 3s\n",
      "86:\tlearn: 0.0489432\ttotal: 6.03s\tremaining: 1m 3s\n",
      "87:\tlearn: 0.0488798\ttotal: 6.09s\tremaining: 1m 3s\n",
      "88:\tlearn: 0.0488223\ttotal: 6.16s\tremaining: 1m 3s\n",
      "89:\tlearn: 0.0487712\ttotal: 6.22s\tremaining: 1m 2s\n",
      "90:\tlearn: 0.0487153\ttotal: 6.28s\tremaining: 1m 2s\n",
      "91:\tlearn: 0.0486650\ttotal: 6.37s\tremaining: 1m 2s\n",
      "92:\tlearn: 0.0486224\ttotal: 6.42s\tremaining: 1m 2s\n",
      "93:\tlearn: 0.0485748\ttotal: 6.49s\tremaining: 1m 2s\n",
      "94:\tlearn: 0.0485200\ttotal: 6.54s\tremaining: 1m 2s\n",
      "95:\tlearn: 0.0484636\ttotal: 6.62s\tremaining: 1m 2s\n",
      "96:\tlearn: 0.0484059\ttotal: 6.7s\tremaining: 1m 2s\n",
      "97:\tlearn: 0.0483602\ttotal: 6.76s\tremaining: 1m 2s\n",
      "98:\tlearn: 0.0483099\ttotal: 6.83s\tremaining: 1m 2s\n",
      "99:\tlearn: 0.0482575\ttotal: 6.9s\tremaining: 1m 2s\n",
      "100:\tlearn: 0.0481984\ttotal: 6.96s\tremaining: 1m 1s\n",
      "101:\tlearn: 0.0481379\ttotal: 7.02s\tremaining: 1m 1s\n",
      "102:\tlearn: 0.0480806\ttotal: 7.09s\tremaining: 1m 1s\n",
      "103:\tlearn: 0.0480272\ttotal: 7.15s\tremaining: 1m 1s\n",
      "104:\tlearn: 0.0479715\ttotal: 7.22s\tremaining: 1m 1s\n",
      "105:\tlearn: 0.0479165\ttotal: 7.31s\tremaining: 1m 1s\n",
      "106:\tlearn: 0.0478690\ttotal: 7.38s\tremaining: 1m 1s\n",
      "107:\tlearn: 0.0478186\ttotal: 7.44s\tremaining: 1m 1s\n",
      "108:\tlearn: 0.0477652\ttotal: 7.5s\tremaining: 1m 1s\n",
      "109:\tlearn: 0.0477246\ttotal: 7.57s\tremaining: 1m 1s\n",
      "110:\tlearn: 0.0476703\ttotal: 7.64s\tremaining: 1m 1s\n",
      "111:\tlearn: 0.0476099\ttotal: 7.7s\tremaining: 1m 1s\n",
      "112:\tlearn: 0.0475671\ttotal: 7.77s\tremaining: 1m\n",
      "113:\tlearn: 0.0475256\ttotal: 7.84s\tremaining: 1m\n",
      "114:\tlearn: 0.0474833\ttotal: 7.91s\tremaining: 1m\n",
      "115:\tlearn: 0.0474399\ttotal: 7.97s\tremaining: 1m\n",
      "116:\tlearn: 0.0473935\ttotal: 8.03s\tremaining: 1m\n",
      "117:\tlearn: 0.0473454\ttotal: 8.1s\tremaining: 1m\n",
      "118:\tlearn: 0.0472852\ttotal: 8.19s\tremaining: 1m\n",
      "119:\tlearn: 0.0472478\ttotal: 8.26s\tremaining: 1m\n",
      "120:\tlearn: 0.0472052\ttotal: 8.33s\tremaining: 1m\n",
      "121:\tlearn: 0.0471601\ttotal: 8.4s\tremaining: 1m\n",
      "122:\tlearn: 0.0471175\ttotal: 8.47s\tremaining: 1m\n",
      "123:\tlearn: 0.0470725\ttotal: 8.53s\tremaining: 1m\n",
      "124:\tlearn: 0.0470292\ttotal: 8.6s\tremaining: 1m\n",
      "125:\tlearn: 0.0469925\ttotal: 8.68s\tremaining: 1m\n",
      "126:\tlearn: 0.0469414\ttotal: 8.76s\tremaining: 1m\n",
      "127:\tlearn: 0.0469076\ttotal: 8.85s\tremaining: 1m\n",
      "128:\tlearn: 0.0468642\ttotal: 8.92s\tremaining: 1m\n",
      "129:\tlearn: 0.0468120\ttotal: 8.99s\tremaining: 1m\n",
      "130:\tlearn: 0.0467689\ttotal: 9.06s\tremaining: 1m\n",
      "131:\tlearn: 0.0467258\ttotal: 9.14s\tremaining: 1m\n",
      "132:\tlearn: 0.0466797\ttotal: 9.22s\tremaining: 1m\n",
      "133:\tlearn: 0.0466414\ttotal: 9.3s\tremaining: 1m\n",
      "134:\tlearn: 0.0466062\ttotal: 9.36s\tremaining: 60s\n",
      "135:\tlearn: 0.0465511\ttotal: 9.43s\tremaining: 59.9s\n",
      "136:\tlearn: 0.0465107\ttotal: 9.5s\tremaining: 59.8s\n",
      "137:\tlearn: 0.0464670\ttotal: 9.56s\tremaining: 59.7s\n",
      "138:\tlearn: 0.0464344\ttotal: 9.64s\tremaining: 59.7s\n",
      "139:\tlearn: 0.0463911\ttotal: 9.71s\tremaining: 59.6s\n",
      "140:\tlearn: 0.0463556\ttotal: 9.77s\tremaining: 59.5s\n",
      "141:\tlearn: 0.0463054\ttotal: 9.85s\tremaining: 59.5s\n",
      "142:\tlearn: 0.0462617\ttotal: 9.92s\tremaining: 59.5s\n",
      "143:\tlearn: 0.0462286\ttotal: 9.98s\tremaining: 59.3s\n",
      "144:\tlearn: 0.0461883\ttotal: 10.1s\tremaining: 59.3s\n",
      "145:\tlearn: 0.0461491\ttotal: 10.1s\tremaining: 59.2s\n",
      "146:\tlearn: 0.0461138\ttotal: 10.2s\tremaining: 59.2s\n",
      "147:\tlearn: 0.0460696\ttotal: 10.3s\tremaining: 59.2s\n",
      "148:\tlearn: 0.0460303\ttotal: 10.4s\tremaining: 59.1s\n",
      "149:\tlearn: 0.0459925\ttotal: 10.4s\tremaining: 59s\n",
      "150:\tlearn: 0.0459598\ttotal: 10.5s\tremaining: 58.9s\n",
      "151:\tlearn: 0.0459268\ttotal: 10.5s\tremaining: 58.8s\n",
      "152:\tlearn: 0.0458901\ttotal: 10.6s\tremaining: 58.8s\n",
      "153:\tlearn: 0.0458470\ttotal: 10.7s\tremaining: 58.7s\n",
      "154:\tlearn: 0.0458022\ttotal: 10.8s\tremaining: 58.6s\n",
      "155:\tlearn: 0.0457737\ttotal: 10.8s\tremaining: 58.6s\n",
      "156:\tlearn: 0.0457346\ttotal: 10.9s\tremaining: 58.5s\n",
      "157:\tlearn: 0.0456965\ttotal: 11s\tremaining: 58.6s\n",
      "158:\tlearn: 0.0456635\ttotal: 11.1s\tremaining: 58.5s\n",
      "159:\tlearn: 0.0456221\ttotal: 11.1s\tremaining: 58.5s\n",
      "160:\tlearn: 0.0455892\ttotal: 11.2s\tremaining: 58.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161:\tlearn: 0.0455550\ttotal: 11.3s\tremaining: 58.4s\n",
      "162:\tlearn: 0.0455195\ttotal: 11.4s\tremaining: 58.3s\n",
      "163:\tlearn: 0.0454845\ttotal: 11.4s\tremaining: 58.2s\n",
      "164:\tlearn: 0.0454496\ttotal: 11.5s\tremaining: 58.1s\n",
      "165:\tlearn: 0.0454090\ttotal: 11.5s\tremaining: 58s\n",
      "166:\tlearn: 0.0453836\ttotal: 11.6s\tremaining: 57.9s\n",
      "167:\tlearn: 0.0453493\ttotal: 11.7s\tremaining: 57.9s\n",
      "168:\tlearn: 0.0453105\ttotal: 11.8s\tremaining: 57.8s\n",
      "169:\tlearn: 0.0452729\ttotal: 11.8s\tremaining: 57.8s\n",
      "170:\tlearn: 0.0452447\ttotal: 11.9s\tremaining: 57.7s\n",
      "171:\tlearn: 0.0452192\ttotal: 12s\tremaining: 57.6s\n",
      "172:\tlearn: 0.0451918\ttotal: 12s\tremaining: 57.5s\n",
      "173:\tlearn: 0.0451655\ttotal: 12.1s\tremaining: 57.4s\n",
      "174:\tlearn: 0.0451326\ttotal: 12.2s\tremaining: 57.4s\n",
      "175:\tlearn: 0.0450983\ttotal: 12.2s\tremaining: 57.3s\n",
      "176:\tlearn: 0.0450536\ttotal: 12.3s\tremaining: 57.3s\n",
      "177:\tlearn: 0.0450253\ttotal: 12.4s\tremaining: 57.2s\n",
      "178:\tlearn: 0.0449947\ttotal: 12.5s\tremaining: 57.2s\n",
      "179:\tlearn: 0.0449639\ttotal: 12.5s\tremaining: 57.1s\n",
      "180:\tlearn: 0.0449292\ttotal: 12.6s\tremaining: 57.1s\n",
      "181:\tlearn: 0.0448981\ttotal: 12.7s\tremaining: 57s\n",
      "182:\tlearn: 0.0448565\ttotal: 12.8s\tremaining: 57s\n",
      "183:\tlearn: 0.0448238\ttotal: 12.8s\tremaining: 57s\n",
      "184:\tlearn: 0.0447914\ttotal: 12.9s\tremaining: 56.9s\n",
      "185:\tlearn: 0.0447638\ttotal: 13s\tremaining: 56.8s\n",
      "186:\tlearn: 0.0447349\ttotal: 13s\tremaining: 56.7s\n",
      "187:\tlearn: 0.0446930\ttotal: 13.1s\tremaining: 56.6s\n",
      "188:\tlearn: 0.0446650\ttotal: 13.2s\tremaining: 56.5s\n",
      "189:\tlearn: 0.0446291\ttotal: 13.2s\tremaining: 56.5s\n",
      "190:\tlearn: 0.0445963\ttotal: 13.3s\tremaining: 56.4s\n",
      "191:\tlearn: 0.0445670\ttotal: 13.4s\tremaining: 56.3s\n",
      "192:\tlearn: 0.0445345\ttotal: 13.4s\tremaining: 56.2s\n",
      "193:\tlearn: 0.0445064\ttotal: 13.5s\tremaining: 56.2s\n",
      "194:\tlearn: 0.0444700\ttotal: 13.6s\tremaining: 56.2s\n",
      "195:\tlearn: 0.0444485\ttotal: 13.7s\tremaining: 56.1s\n",
      "196:\tlearn: 0.0444202\ttotal: 13.8s\tremaining: 56.1s\n",
      "197:\tlearn: 0.0443863\ttotal: 13.8s\tremaining: 56s\n",
      "198:\tlearn: 0.0443580\ttotal: 13.9s\tremaining: 55.9s\n",
      "199:\tlearn: 0.0443279\ttotal: 14s\tremaining: 55.9s\n",
      "200:\tlearn: 0.0442962\ttotal: 14s\tremaining: 55.8s\n",
      "201:\tlearn: 0.0442593\ttotal: 14.1s\tremaining: 55.8s\n",
      "202:\tlearn: 0.0442289\ttotal: 14.2s\tremaining: 55.8s\n",
      "203:\tlearn: 0.0441997\ttotal: 14.3s\tremaining: 55.7s\n",
      "204:\tlearn: 0.0441763\ttotal: 14.3s\tremaining: 55.6s\n",
      "205:\tlearn: 0.0441486\ttotal: 14.4s\tremaining: 55.5s\n",
      "206:\tlearn: 0.0441223\ttotal: 14.5s\tremaining: 55.4s\n",
      "207:\tlearn: 0.0440949\ttotal: 14.5s\tremaining: 55.4s\n",
      "208:\tlearn: 0.0440580\ttotal: 14.6s\tremaining: 55.3s\n",
      "209:\tlearn: 0.0440247\ttotal: 14.7s\tremaining: 55.3s\n",
      "210:\tlearn: 0.0440008\ttotal: 14.8s\tremaining: 55.2s\n",
      "211:\tlearn: 0.0439726\ttotal: 14.8s\tremaining: 55.1s\n",
      "212:\tlearn: 0.0439452\ttotal: 14.9s\tremaining: 55.1s\n",
      "213:\tlearn: 0.0439126\ttotal: 15s\tremaining: 55s\n",
      "214:\tlearn: 0.0438849\ttotal: 15s\tremaining: 54.9s\n",
      "215:\tlearn: 0.0438640\ttotal: 15.1s\tremaining: 54.8s\n",
      "216:\tlearn: 0.0438371\ttotal: 15.2s\tremaining: 54.8s\n",
      "217:\tlearn: 0.0438052\ttotal: 15.2s\tremaining: 54.7s\n",
      "218:\tlearn: 0.0437704\ttotal: 15.3s\tremaining: 54.7s\n",
      "219:\tlearn: 0.0437365\ttotal: 15.4s\tremaining: 54.7s\n",
      "220:\tlearn: 0.0437116\ttotal: 15.5s\tremaining: 54.6s\n",
      "221:\tlearn: 0.0436857\ttotal: 15.6s\tremaining: 54.6s\n",
      "222:\tlearn: 0.0436571\ttotal: 15.6s\tremaining: 54.5s\n",
      "223:\tlearn: 0.0436346\ttotal: 15.7s\tremaining: 54.4s\n",
      "224:\tlearn: 0.0436062\ttotal: 15.8s\tremaining: 54.3s\n",
      "225:\tlearn: 0.0435806\ttotal: 15.9s\tremaining: 54.3s\n",
      "226:\tlearn: 0.0435523\ttotal: 15.9s\tremaining: 54.2s\n",
      "227:\tlearn: 0.0435334\ttotal: 16s\tremaining: 54.2s\n",
      "228:\tlearn: 0.0435092\ttotal: 16.1s\tremaining: 54.1s\n",
      "229:\tlearn: 0.0434816\ttotal: 16.2s\tremaining: 54.1s\n",
      "230:\tlearn: 0.0434581\ttotal: 16.2s\tremaining: 54.1s\n",
      "231:\tlearn: 0.0434301\ttotal: 16.3s\tremaining: 54s\n",
      "232:\tlearn: 0.0434096\ttotal: 16.4s\tremaining: 53.9s\n",
      "233:\tlearn: 0.0433780\ttotal: 16.5s\tremaining: 53.9s\n",
      "234:\tlearn: 0.0433519\ttotal: 16.5s\tremaining: 53.8s\n",
      "235:\tlearn: 0.0433288\ttotal: 16.6s\tremaining: 53.8s\n",
      "236:\tlearn: 0.0433035\ttotal: 16.7s\tremaining: 53.7s\n",
      "237:\tlearn: 0.0432759\ttotal: 16.8s\tremaining: 53.7s\n",
      "238:\tlearn: 0.0432442\ttotal: 16.8s\tremaining: 53.6s\n",
      "239:\tlearn: 0.0432177\ttotal: 16.9s\tremaining: 53.5s\n",
      "240:\tlearn: 0.0431875\ttotal: 17s\tremaining: 53.5s\n",
      "241:\tlearn: 0.0431672\ttotal: 17.1s\tremaining: 53.4s\n",
      "242:\tlearn: 0.0431420\ttotal: 17.1s\tremaining: 53.4s\n",
      "243:\tlearn: 0.0431107\ttotal: 17.2s\tremaining: 53.3s\n",
      "244:\tlearn: 0.0430804\ttotal: 17.3s\tremaining: 53.2s\n",
      "245:\tlearn: 0.0430528\ttotal: 17.4s\tremaining: 53.2s\n",
      "246:\tlearn: 0.0430337\ttotal: 17.4s\tremaining: 53.1s\n",
      "247:\tlearn: 0.0430085\ttotal: 17.5s\tremaining: 53.1s\n",
      "248:\tlearn: 0.0429837\ttotal: 17.6s\tremaining: 53s\n",
      "249:\tlearn: 0.0429613\ttotal: 17.6s\tremaining: 52.9s\n",
      "250:\tlearn: 0.0429360\ttotal: 17.7s\tremaining: 52.9s\n",
      "251:\tlearn: 0.0429143\ttotal: 17.8s\tremaining: 52.8s\n",
      "252:\tlearn: 0.0428960\ttotal: 17.9s\tremaining: 52.7s\n",
      "253:\tlearn: 0.0428615\ttotal: 17.9s\tremaining: 52.7s\n",
      "254:\tlearn: 0.0428412\ttotal: 18s\tremaining: 52.7s\n",
      "255:\tlearn: 0.0428208\ttotal: 18.1s\tremaining: 52.6s\n",
      "256:\tlearn: 0.0427968\ttotal: 18.2s\tremaining: 52.5s\n",
      "257:\tlearn: 0.0427718\ttotal: 18.3s\tremaining: 52.5s\n",
      "258:\tlearn: 0.0427472\ttotal: 18.3s\tremaining: 52.4s\n",
      "259:\tlearn: 0.0427240\ttotal: 18.4s\tremaining: 52.4s\n",
      "260:\tlearn: 0.0427048\ttotal: 18.5s\tremaining: 52.3s\n",
      "261:\tlearn: 0.0426882\ttotal: 18.5s\tremaining: 52.2s\n",
      "262:\tlearn: 0.0426650\ttotal: 18.6s\tremaining: 52.1s\n",
      "263:\tlearn: 0.0426397\ttotal: 18.7s\tremaining: 52.1s\n",
      "264:\tlearn: 0.0426154\ttotal: 18.7s\tremaining: 52s\n",
      "265:\tlearn: 0.0425923\ttotal: 18.8s\tremaining: 51.9s\n",
      "266:\tlearn: 0.0425652\ttotal: 18.9s\tremaining: 51.9s\n",
      "267:\tlearn: 0.0425387\ttotal: 19s\tremaining: 51.8s\n",
      "268:\tlearn: 0.0425105\ttotal: 19.1s\tremaining: 51.8s\n",
      "269:\tlearn: 0.0424834\ttotal: 19.1s\tremaining: 51.7s\n",
      "270:\tlearn: 0.0424588\ttotal: 19.2s\tremaining: 51.7s\n",
      "271:\tlearn: 0.0424341\ttotal: 19.3s\tremaining: 51.6s\n",
      "272:\tlearn: 0.0424130\ttotal: 19.4s\tremaining: 51.5s\n",
      "273:\tlearn: 0.0423918\ttotal: 19.4s\tremaining: 51.4s\n",
      "274:\tlearn: 0.0423739\ttotal: 19.5s\tremaining: 51.4s\n",
      "275:\tlearn: 0.0423453\ttotal: 19.6s\tremaining: 51.4s\n",
      "276:\tlearn: 0.0423299\ttotal: 19.7s\tremaining: 51.3s\n",
      "277:\tlearn: 0.0423003\ttotal: 19.8s\tremaining: 51.4s\n",
      "278:\tlearn: 0.0422805\ttotal: 19.9s\tremaining: 51.3s\n",
      "279:\tlearn: 0.0422621\ttotal: 19.9s\tremaining: 51.3s\n",
      "280:\tlearn: 0.0422438\ttotal: 20s\tremaining: 51.2s\n",
      "281:\tlearn: 0.0422247\ttotal: 20.1s\tremaining: 51.1s\n",
      "282:\tlearn: 0.0422034\ttotal: 20.1s\tremaining: 51s\n",
      "283:\tlearn: 0.0421831\ttotal: 20.2s\tremaining: 51s\n",
      "284:\tlearn: 0.0421593\ttotal: 20.3s\tremaining: 50.9s\n",
      "285:\tlearn: 0.0421364\ttotal: 20.4s\tremaining: 50.8s\n",
      "286:\tlearn: 0.0421108\ttotal: 20.5s\tremaining: 50.8s\n",
      "287:\tlearn: 0.0420932\ttotal: 20.5s\tremaining: 50.7s\n",
      "288:\tlearn: 0.0420665\ttotal: 20.6s\tremaining: 50.7s\n",
      "289:\tlearn: 0.0420453\ttotal: 20.7s\tremaining: 50.7s\n",
      "290:\tlearn: 0.0420245\ttotal: 20.8s\tremaining: 50.6s\n",
      "291:\tlearn: 0.0420042\ttotal: 20.8s\tremaining: 50.6s\n",
      "292:\tlearn: 0.0419838\ttotal: 20.9s\tremaining: 50.5s\n",
      "293:\tlearn: 0.0419607\ttotal: 21s\tremaining: 50.4s\n",
      "294:\tlearn: 0.0419404\ttotal: 21s\tremaining: 50.3s\n",
      "295:\tlearn: 0.0419191\ttotal: 21.1s\tremaining: 50.2s\n",
      "296:\tlearn: 0.0418940\ttotal: 21.2s\tremaining: 50.2s\n",
      "297:\tlearn: 0.0418712\ttotal: 21.3s\tremaining: 50.1s\n",
      "298:\tlearn: 0.0418545\ttotal: 21.3s\tremaining: 50s\n",
      "299:\tlearn: 0.0418404\ttotal: 21.4s\tremaining: 49.9s\n",
      "300:\tlearn: 0.0418141\ttotal: 21.5s\tremaining: 49.9s\n",
      "301:\tlearn: 0.0417939\ttotal: 21.5s\tremaining: 49.8s\n",
      "302:\tlearn: 0.0417747\ttotal: 21.6s\tremaining: 49.8s\n",
      "303:\tlearn: 0.0417551\ttotal: 21.7s\tremaining: 49.7s\n",
      "304:\tlearn: 0.0417318\ttotal: 21.8s\tremaining: 49.7s\n",
      "305:\tlearn: 0.0417150\ttotal: 21.9s\tremaining: 49.6s\n",
      "306:\tlearn: 0.0416973\ttotal: 21.9s\tremaining: 49.5s\n",
      "307:\tlearn: 0.0416784\ttotal: 22s\tremaining: 49.4s\n",
      "308:\tlearn: 0.0416576\ttotal: 22s\tremaining: 49.3s\n",
      "309:\tlearn: 0.0416363\ttotal: 22.1s\tremaining: 49.2s\n",
      "310:\tlearn: 0.0416162\ttotal: 22.2s\tremaining: 49.2s\n",
      "311:\tlearn: 0.0415940\ttotal: 22.3s\tremaining: 49.1s\n",
      "312:\tlearn: 0.0415790\ttotal: 22.3s\tremaining: 49s\n",
      "313:\tlearn: 0.0415573\ttotal: 22.4s\tremaining: 49s\n",
      "314:\tlearn: 0.0415389\ttotal: 22.5s\tremaining: 48.9s\n",
      "315:\tlearn: 0.0415222\ttotal: 22.6s\tremaining: 48.8s\n",
      "316:\tlearn: 0.0414977\ttotal: 22.6s\tremaining: 48.7s\n",
      "317:\tlearn: 0.0414844\ttotal: 22.7s\tremaining: 48.7s\n",
      "318:\tlearn: 0.0414584\ttotal: 22.8s\tremaining: 48.6s\n",
      "319:\tlearn: 0.0414430\ttotal: 22.8s\tremaining: 48.5s\n",
      "320:\tlearn: 0.0414239\ttotal: 22.9s\tremaining: 48.4s\n",
      "321:\tlearn: 0.0414123\ttotal: 23s\tremaining: 48.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322:\tlearn: 0.0413931\ttotal: 23s\tremaining: 48.3s\n",
      "323:\tlearn: 0.0413681\ttotal: 23.1s\tremaining: 48.2s\n",
      "324:\tlearn: 0.0413526\ttotal: 23.2s\tremaining: 48.1s\n",
      "325:\tlearn: 0.0413290\ttotal: 23.2s\tremaining: 48.1s\n",
      "326:\tlearn: 0.0413122\ttotal: 23.3s\tremaining: 48s\n",
      "327:\tlearn: 0.0412864\ttotal: 23.4s\tremaining: 47.9s\n",
      "328:\tlearn: 0.0412653\ttotal: 23.5s\tremaining: 47.9s\n",
      "329:\tlearn: 0.0412465\ttotal: 23.5s\tremaining: 47.8s\n",
      "330:\tlearn: 0.0412289\ttotal: 23.6s\tremaining: 47.7s\n",
      "331:\tlearn: 0.0412178\ttotal: 23.7s\tremaining: 47.6s\n",
      "332:\tlearn: 0.0412008\ttotal: 23.7s\tremaining: 47.6s\n",
      "333:\tlearn: 0.0411816\ttotal: 23.8s\tremaining: 47.5s\n",
      "334:\tlearn: 0.0411624\ttotal: 23.9s\tremaining: 47.5s\n",
      "335:\tlearn: 0.0411457\ttotal: 24s\tremaining: 47.4s\n",
      "336:\tlearn: 0.0411269\ttotal: 24.1s\tremaining: 47.3s\n",
      "337:\tlearn: 0.0411028\ttotal: 24.1s\tremaining: 47.3s\n",
      "338:\tlearn: 0.0410836\ttotal: 24.2s\tremaining: 47.2s\n",
      "339:\tlearn: 0.0410598\ttotal: 24.3s\tremaining: 47.1s\n",
      "340:\tlearn: 0.0410389\ttotal: 24.4s\tremaining: 47.1s\n",
      "341:\tlearn: 0.0410112\ttotal: 24.5s\tremaining: 47.1s\n",
      "342:\tlearn: 0.0409916\ttotal: 24.5s\tremaining: 47s\n",
      "343:\tlearn: 0.0409700\ttotal: 24.6s\tremaining: 46.9s\n",
      "344:\tlearn: 0.0409486\ttotal: 24.7s\tremaining: 46.9s\n",
      "345:\tlearn: 0.0409231\ttotal: 24.8s\tremaining: 46.8s\n",
      "346:\tlearn: 0.0409051\ttotal: 24.8s\tremaining: 46.8s\n",
      "347:\tlearn: 0.0408877\ttotal: 24.9s\tremaining: 46.7s\n",
      "348:\tlearn: 0.0408653\ttotal: 25s\tremaining: 46.6s\n",
      "349:\tlearn: 0.0408402\ttotal: 25.1s\tremaining: 46.5s\n",
      "350:\tlearn: 0.0408218\ttotal: 25.1s\tremaining: 46.4s\n",
      "351:\tlearn: 0.0408032\ttotal: 25.2s\tremaining: 46.4s\n",
      "352:\tlearn: 0.0407895\ttotal: 25.3s\tremaining: 46.3s\n",
      "353:\tlearn: 0.0407663\ttotal: 25.3s\tremaining: 46.2s\n",
      "354:\tlearn: 0.0407478\ttotal: 25.4s\tremaining: 46.1s\n",
      "355:\tlearn: 0.0407295\ttotal: 25.5s\tremaining: 46s\n",
      "356:\tlearn: 0.0407211\ttotal: 25.5s\tremaining: 46s\n",
      "357:\tlearn: 0.0406982\ttotal: 25.6s\tremaining: 45.9s\n",
      "358:\tlearn: 0.0406806\ttotal: 25.6s\tremaining: 45.8s\n",
      "359:\tlearn: 0.0406675\ttotal: 25.7s\tremaining: 45.7s\n",
      "360:\tlearn: 0.0406514\ttotal: 25.8s\tremaining: 45.6s\n",
      "361:\tlearn: 0.0406359\ttotal: 25.8s\tremaining: 45.6s\n",
      "362:\tlearn: 0.0406254\ttotal: 25.9s\tremaining: 45.5s\n",
      "363:\tlearn: 0.0406051\ttotal: 26s\tremaining: 45.4s\n",
      "364:\tlearn: 0.0405835\ttotal: 26s\tremaining: 45.3s\n",
      "365:\tlearn: 0.0405682\ttotal: 26.1s\tremaining: 45.2s\n",
      "366:\tlearn: 0.0405500\ttotal: 26.2s\tremaining: 45.1s\n",
      "367:\tlearn: 0.0405361\ttotal: 26.2s\tremaining: 45.1s\n",
      "368:\tlearn: 0.0405149\ttotal: 26.3s\tremaining: 45s\n",
      "369:\tlearn: 0.0405008\ttotal: 26.4s\tremaining: 44.9s\n",
      "370:\tlearn: 0.0405006\ttotal: 26.4s\tremaining: 44.8s\n",
      "371:\tlearn: 0.0404922\ttotal: 26.5s\tremaining: 44.7s\n",
      "372:\tlearn: 0.0404918\ttotal: 26.5s\tremaining: 44.6s\n",
      "373:\tlearn: 0.0404762\ttotal: 26.6s\tremaining: 44.5s\n",
      "374:\tlearn: 0.0404566\ttotal: 26.7s\tremaining: 44.5s\n",
      "375:\tlearn: 0.0404563\ttotal: 26.7s\tremaining: 44.4s\n",
      "376:\tlearn: 0.0404411\ttotal: 26.8s\tremaining: 44.3s\n",
      "377:\tlearn: 0.0404284\ttotal: 26.9s\tremaining: 44.2s\n",
      "378:\tlearn: 0.0404153\ttotal: 27s\tremaining: 44.2s\n",
      "379:\tlearn: 0.0404150\ttotal: 27s\tremaining: 44.1s\n",
      "380:\tlearn: 0.0404149\ttotal: 27.1s\tremaining: 44s\n",
      "381:\tlearn: 0.0404144\ttotal: 27.1s\tremaining: 43.9s\n",
      "382:\tlearn: 0.0404014\ttotal: 27.2s\tremaining: 43.8s\n",
      "383:\tlearn: 0.0403805\ttotal: 27.3s\tremaining: 43.8s\n",
      "384:\tlearn: 0.0403591\ttotal: 27.4s\tremaining: 43.7s\n",
      "385:\tlearn: 0.0403468\ttotal: 27.4s\tremaining: 43.6s\n",
      "386:\tlearn: 0.0403271\ttotal: 27.5s\tremaining: 43.6s\n",
      "387:\tlearn: 0.0403117\ttotal: 27.6s\tremaining: 43.5s\n",
      "388:\tlearn: 0.0402985\ttotal: 27.7s\tremaining: 43.5s\n",
      "389:\tlearn: 0.0402840\ttotal: 27.7s\tremaining: 43.4s\n",
      "390:\tlearn: 0.0402663\ttotal: 27.8s\tremaining: 43.3s\n",
      "391:\tlearn: 0.0402526\ttotal: 27.9s\tremaining: 43.3s\n",
      "392:\tlearn: 0.0402396\ttotal: 28s\tremaining: 43.2s\n",
      "393:\tlearn: 0.0402200\ttotal: 28s\tremaining: 43.1s\n",
      "394:\tlearn: 0.0402194\ttotal: 28.1s\tremaining: 43s\n",
      "395:\tlearn: 0.0402193\ttotal: 28.1s\tremaining: 42.9s\n",
      "396:\tlearn: 0.0401997\ttotal: 28.2s\tremaining: 42.9s\n",
      "397:\tlearn: 0.0401875\ttotal: 28.3s\tremaining: 42.8s\n",
      "398:\tlearn: 0.0401658\ttotal: 28.4s\tremaining: 42.7s\n",
      "399:\tlearn: 0.0401535\ttotal: 28.4s\tremaining: 42.7s\n",
      "400:\tlearn: 0.0401428\ttotal: 28.5s\tremaining: 42.6s\n",
      "401:\tlearn: 0.0401298\ttotal: 28.6s\tremaining: 42.5s\n",
      "402:\tlearn: 0.0401104\ttotal: 28.7s\tremaining: 42.5s\n",
      "403:\tlearn: 0.0400927\ttotal: 28.7s\tremaining: 42.4s\n",
      "404:\tlearn: 0.0400782\ttotal: 28.8s\tremaining: 42.3s\n",
      "405:\tlearn: 0.0400586\ttotal: 28.9s\tremaining: 42.3s\n",
      "406:\tlearn: 0.0400406\ttotal: 29s\tremaining: 42.2s\n",
      "407:\tlearn: 0.0400250\ttotal: 29.1s\tremaining: 42.2s\n",
      "408:\tlearn: 0.0400078\ttotal: 29.1s\tremaining: 42.1s\n",
      "409:\tlearn: 0.0399892\ttotal: 29.2s\tremaining: 42s\n",
      "410:\tlearn: 0.0399735\ttotal: 29.3s\tremaining: 42s\n",
      "411:\tlearn: 0.0399603\ttotal: 29.3s\tremaining: 41.9s\n",
      "412:\tlearn: 0.0399601\ttotal: 29.4s\tremaining: 41.8s\n",
      "413:\tlearn: 0.0399459\ttotal: 29.5s\tremaining: 41.7s\n",
      "414:\tlearn: 0.0399288\ttotal: 29.5s\tremaining: 41.6s\n",
      "415:\tlearn: 0.0399193\ttotal: 29.6s\tremaining: 41.5s\n",
      "416:\tlearn: 0.0399090\ttotal: 29.7s\tremaining: 41.5s\n",
      "417:\tlearn: 0.0398969\ttotal: 29.7s\tremaining: 41.4s\n",
      "418:\tlearn: 0.0398967\ttotal: 29.8s\tremaining: 41.3s\n",
      "419:\tlearn: 0.0398821\ttotal: 29.9s\tremaining: 41.3s\n",
      "420:\tlearn: 0.0398658\ttotal: 29.9s\tremaining: 41.2s\n",
      "421:\tlearn: 0.0398656\ttotal: 30s\tremaining: 41.1s\n",
      "422:\tlearn: 0.0398542\ttotal: 30.1s\tremaining: 41s\n",
      "423:\tlearn: 0.0398368\ttotal: 30.2s\tremaining: 41s\n",
      "424:\tlearn: 0.0398364\ttotal: 30.2s\tremaining: 40.9s\n",
      "425:\tlearn: 0.0398143\ttotal: 30.3s\tremaining: 40.8s\n",
      "426:\tlearn: 0.0398038\ttotal: 30.4s\tremaining: 40.8s\n",
      "427:\tlearn: 0.0397832\ttotal: 30.4s\tremaining: 40.7s\n",
      "428:\tlearn: 0.0397703\ttotal: 30.5s\tremaining: 40.6s\n",
      "429:\tlearn: 0.0397591\ttotal: 30.6s\tremaining: 40.6s\n",
      "430:\tlearn: 0.0397525\ttotal: 30.7s\tremaining: 40.5s\n",
      "431:\tlearn: 0.0397320\ttotal: 30.7s\tremaining: 40.4s\n",
      "432:\tlearn: 0.0397192\ttotal: 30.8s\tremaining: 40.3s\n",
      "433:\tlearn: 0.0397063\ttotal: 30.9s\tremaining: 40.3s\n",
      "434:\tlearn: 0.0396920\ttotal: 30.9s\tremaining: 40.2s\n",
      "435:\tlearn: 0.0396704\ttotal: 31s\tremaining: 40.1s\n",
      "436:\tlearn: 0.0396700\ttotal: 31.1s\tremaining: 40s\n",
      "437:\tlearn: 0.0396562\ttotal: 31.1s\tremaining: 39.9s\n",
      "438:\tlearn: 0.0396464\ttotal: 31.2s\tremaining: 39.9s\n",
      "439:\tlearn: 0.0396462\ttotal: 31.2s\tremaining: 39.8s\n",
      "440:\tlearn: 0.0396325\ttotal: 31.3s\tremaining: 39.7s\n",
      "441:\tlearn: 0.0396324\ttotal: 31.4s\tremaining: 39.6s\n",
      "442:\tlearn: 0.0396319\ttotal: 31.4s\tremaining: 39.5s\n",
      "443:\tlearn: 0.0396187\ttotal: 31.5s\tremaining: 39.4s\n",
      "444:\tlearn: 0.0396184\ttotal: 31.5s\tremaining: 39.3s\n",
      "445:\tlearn: 0.0396045\ttotal: 31.6s\tremaining: 39.3s\n",
      "446:\tlearn: 0.0395894\ttotal: 31.7s\tremaining: 39.2s\n",
      "447:\tlearn: 0.0395893\ttotal: 31.7s\tremaining: 39.1s\n",
      "448:\tlearn: 0.0395655\ttotal: 31.8s\tremaining: 39s\n",
      "449:\tlearn: 0.0395414\ttotal: 31.9s\tremaining: 39s\n",
      "450:\tlearn: 0.0395258\ttotal: 32s\tremaining: 38.9s\n",
      "451:\tlearn: 0.0395116\ttotal: 32s\tremaining: 38.8s\n",
      "452:\tlearn: 0.0395015\ttotal: 32.1s\tremaining: 38.8s\n",
      "453:\tlearn: 0.0394869\ttotal: 32.2s\tremaining: 38.7s\n",
      "454:\tlearn: 0.0394762\ttotal: 32.3s\tremaining: 38.6s\n",
      "455:\tlearn: 0.0394621\ttotal: 32.3s\tremaining: 38.6s\n",
      "456:\tlearn: 0.0394443\ttotal: 32.4s\tremaining: 38.5s\n",
      "457:\tlearn: 0.0394316\ttotal: 32.5s\tremaining: 38.4s\n",
      "458:\tlearn: 0.0394168\ttotal: 32.5s\tremaining: 38.3s\n",
      "459:\tlearn: 0.0394016\ttotal: 32.6s\tremaining: 38.3s\n",
      "460:\tlearn: 0.0393868\ttotal: 32.7s\tremaining: 38.2s\n",
      "461:\tlearn: 0.0393711\ttotal: 32.8s\tremaining: 38.1s\n",
      "462:\tlearn: 0.0393560\ttotal: 32.8s\tremaining: 38.1s\n",
      "463:\tlearn: 0.0393450\ttotal: 32.9s\tremaining: 38s\n",
      "464:\tlearn: 0.0393287\ttotal: 32.9s\tremaining: 37.9s\n",
      "465:\tlearn: 0.0393172\ttotal: 33s\tremaining: 37.8s\n",
      "466:\tlearn: 0.0393018\ttotal: 33.1s\tremaining: 37.8s\n",
      "467:\tlearn: 0.0392782\ttotal: 33.2s\tremaining: 37.7s\n",
      "468:\tlearn: 0.0392689\ttotal: 33.2s\tremaining: 37.6s\n",
      "469:\tlearn: 0.0392577\ttotal: 33.3s\tremaining: 37.6s\n",
      "470:\tlearn: 0.0392459\ttotal: 33.4s\tremaining: 37.5s\n",
      "471:\tlearn: 0.0392306\ttotal: 33.5s\tremaining: 37.4s\n",
      "472:\tlearn: 0.0392174\ttotal: 33.5s\tremaining: 37.4s\n",
      "473:\tlearn: 0.0392083\ttotal: 33.6s\tremaining: 37.3s\n",
      "474:\tlearn: 0.0391960\ttotal: 33.7s\tremaining: 37.2s\n",
      "475:\tlearn: 0.0391836\ttotal: 33.7s\tremaining: 37.1s\n",
      "476:\tlearn: 0.0391666\ttotal: 33.8s\tremaining: 37.1s\n",
      "477:\tlearn: 0.0391571\ttotal: 33.9s\tremaining: 37s\n",
      "478:\tlearn: 0.0391437\ttotal: 34s\tremaining: 36.9s\n",
      "479:\tlearn: 0.0391291\ttotal: 34s\tremaining: 36.9s\n",
      "480:\tlearn: 0.0391178\ttotal: 34.1s\tremaining: 36.8s\n",
      "481:\tlearn: 0.0390979\ttotal: 34.2s\tremaining: 36.7s\n",
      "482:\tlearn: 0.0390841\ttotal: 34.2s\tremaining: 36.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483:\tlearn: 0.0390646\ttotal: 34.3s\tremaining: 36.6s\n",
      "484:\tlearn: 0.0390570\ttotal: 34.4s\tremaining: 36.5s\n",
      "485:\tlearn: 0.0390568\ttotal: 34.4s\tremaining: 36.4s\n",
      "486:\tlearn: 0.0390375\ttotal: 34.5s\tremaining: 36.3s\n",
      "487:\tlearn: 0.0390255\ttotal: 34.6s\tremaining: 36.3s\n",
      "488:\tlearn: 0.0390064\ttotal: 34.6s\tremaining: 36.2s\n",
      "489:\tlearn: 0.0389875\ttotal: 34.7s\tremaining: 36.1s\n",
      "490:\tlearn: 0.0389729\ttotal: 34.8s\tremaining: 36.1s\n",
      "491:\tlearn: 0.0389634\ttotal: 34.8s\tremaining: 36s\n",
      "492:\tlearn: 0.0389504\ttotal: 34.9s\tremaining: 35.9s\n",
      "493:\tlearn: 0.0389372\ttotal: 35s\tremaining: 35.8s\n",
      "494:\tlearn: 0.0389239\ttotal: 35s\tremaining: 35.8s\n",
      "495:\tlearn: 0.0389162\ttotal: 35.1s\tremaining: 35.7s\n",
      "496:\tlearn: 0.0389047\ttotal: 35.2s\tremaining: 35.6s\n",
      "497:\tlearn: 0.0388974\ttotal: 35.2s\tremaining: 35.5s\n",
      "498:\tlearn: 0.0388874\ttotal: 35.3s\tremaining: 35.5s\n",
      "499:\tlearn: 0.0388783\ttotal: 35.4s\tremaining: 35.4s\n",
      "500:\tlearn: 0.0388779\ttotal: 35.4s\tremaining: 35.3s\n",
      "501:\tlearn: 0.0388707\ttotal: 35.5s\tremaining: 35.2s\n",
      "502:\tlearn: 0.0388607\ttotal: 35.5s\tremaining: 35.1s\n",
      "503:\tlearn: 0.0388498\ttotal: 35.6s\tremaining: 35s\n",
      "504:\tlearn: 0.0388497\ttotal: 35.7s\tremaining: 35s\n",
      "505:\tlearn: 0.0388325\ttotal: 35.7s\tremaining: 34.9s\n",
      "506:\tlearn: 0.0388183\ttotal: 35.8s\tremaining: 34.8s\n",
      "507:\tlearn: 0.0388068\ttotal: 35.9s\tremaining: 34.8s\n",
      "508:\tlearn: 0.0387940\ttotal: 35.9s\tremaining: 34.7s\n",
      "509:\tlearn: 0.0387780\ttotal: 36s\tremaining: 34.6s\n",
      "510:\tlearn: 0.0387675\ttotal: 36.1s\tremaining: 34.5s\n",
      "511:\tlearn: 0.0387569\ttotal: 36.1s\tremaining: 34.5s\n",
      "512:\tlearn: 0.0387475\ttotal: 36.2s\tremaining: 34.4s\n",
      "513:\tlearn: 0.0387359\ttotal: 36.3s\tremaining: 34.3s\n",
      "514:\tlearn: 0.0387357\ttotal: 36.3s\tremaining: 34.2s\n",
      "515:\tlearn: 0.0387175\ttotal: 36.4s\tremaining: 34.1s\n",
      "516:\tlearn: 0.0387064\ttotal: 36.5s\tremaining: 34.1s\n",
      "517:\tlearn: 0.0386978\ttotal: 36.5s\tremaining: 34s\n",
      "518:\tlearn: 0.0386852\ttotal: 36.6s\tremaining: 33.9s\n",
      "519:\tlearn: 0.0386748\ttotal: 36.7s\tremaining: 33.8s\n",
      "520:\tlearn: 0.0386746\ttotal: 36.7s\tremaining: 33.8s\n",
      "521:\tlearn: 0.0386677\ttotal: 36.8s\tremaining: 33.7s\n",
      "522:\tlearn: 0.0386529\ttotal: 36.9s\tremaining: 33.7s\n",
      "523:\tlearn: 0.0386527\ttotal: 37s\tremaining: 33.6s\n",
      "524:\tlearn: 0.0386432\ttotal: 37s\tremaining: 33.5s\n",
      "525:\tlearn: 0.0386247\ttotal: 37.1s\tremaining: 33.5s\n",
      "526:\tlearn: 0.0386121\ttotal: 37.2s\tremaining: 33.4s\n",
      "527:\tlearn: 0.0386033\ttotal: 37.2s\tremaining: 33.3s\n",
      "528:\tlearn: 0.0385869\ttotal: 37.3s\tremaining: 33.2s\n",
      "529:\tlearn: 0.0385750\ttotal: 37.4s\tremaining: 33.2s\n",
      "530:\tlearn: 0.0385648\ttotal: 37.4s\tremaining: 33.1s\n",
      "531:\tlearn: 0.0385504\ttotal: 37.5s\tremaining: 33s\n",
      "532:\tlearn: 0.0385323\ttotal: 37.6s\tremaining: 32.9s\n",
      "533:\tlearn: 0.0385230\ttotal: 37.7s\tremaining: 32.9s\n",
      "534:\tlearn: 0.0385044\ttotal: 37.7s\tremaining: 32.8s\n",
      "535:\tlearn: 0.0384933\ttotal: 37.8s\tremaining: 32.7s\n",
      "536:\tlearn: 0.0384740\ttotal: 37.9s\tremaining: 32.7s\n",
      "537:\tlearn: 0.0384587\ttotal: 37.9s\tremaining: 32.6s\n",
      "538:\tlearn: 0.0384438\ttotal: 38s\tremaining: 32.5s\n",
      "539:\tlearn: 0.0384325\ttotal: 38.1s\tremaining: 32.4s\n",
      "540:\tlearn: 0.0384161\ttotal: 38.1s\tremaining: 32.4s\n",
      "541:\tlearn: 0.0384041\ttotal: 38.2s\tremaining: 32.3s\n",
      "542:\tlearn: 0.0383903\ttotal: 38.3s\tremaining: 32.2s\n",
      "543:\tlearn: 0.0383779\ttotal: 38.4s\tremaining: 32.2s\n",
      "544:\tlearn: 0.0383697\ttotal: 38.4s\tremaining: 32.1s\n",
      "545:\tlearn: 0.0383601\ttotal: 38.5s\tremaining: 32s\n",
      "546:\tlearn: 0.0383432\ttotal: 38.6s\tremaining: 31.9s\n",
      "547:\tlearn: 0.0383294\ttotal: 38.6s\tremaining: 31.9s\n",
      "548:\tlearn: 0.0383156\ttotal: 38.7s\tremaining: 31.8s\n",
      "549:\tlearn: 0.0383040\ttotal: 38.8s\tremaining: 31.7s\n",
      "550:\tlearn: 0.0382928\ttotal: 38.8s\tremaining: 31.7s\n",
      "551:\tlearn: 0.0382804\ttotal: 38.9s\tremaining: 31.6s\n",
      "552:\tlearn: 0.0382729\ttotal: 39s\tremaining: 31.5s\n",
      "553:\tlearn: 0.0382564\ttotal: 39s\tremaining: 31.4s\n",
      "554:\tlearn: 0.0382430\ttotal: 39.1s\tremaining: 31.4s\n",
      "555:\tlearn: 0.0382349\ttotal: 39.2s\tremaining: 31.3s\n",
      "556:\tlearn: 0.0382313\ttotal: 39.2s\tremaining: 31.2s\n",
      "557:\tlearn: 0.0382206\ttotal: 39.3s\tremaining: 31.1s\n",
      "558:\tlearn: 0.0382119\ttotal: 39.4s\tremaining: 31.1s\n",
      "559:\tlearn: 0.0382029\ttotal: 39.4s\tremaining: 31s\n",
      "560:\tlearn: 0.0381869\ttotal: 39.5s\tremaining: 30.9s\n",
      "561:\tlearn: 0.0381812\ttotal: 39.6s\tremaining: 30.8s\n",
      "562:\tlearn: 0.0381657\ttotal: 39.6s\tremaining: 30.8s\n",
      "563:\tlearn: 0.0381655\ttotal: 39.7s\tremaining: 30.7s\n",
      "564:\tlearn: 0.0381556\ttotal: 39.7s\tremaining: 30.6s\n",
      "565:\tlearn: 0.0381444\ttotal: 39.8s\tremaining: 30.5s\n",
      "566:\tlearn: 0.0381328\ttotal: 39.9s\tremaining: 30.5s\n",
      "567:\tlearn: 0.0381237\ttotal: 40s\tremaining: 30.4s\n",
      "568:\tlearn: 0.0381110\ttotal: 40s\tremaining: 30.3s\n",
      "569:\tlearn: 0.0381109\ttotal: 40.1s\tremaining: 30.2s\n",
      "570:\tlearn: 0.0381106\ttotal: 40.1s\tremaining: 30.2s\n",
      "571:\tlearn: 0.0380919\ttotal: 40.2s\tremaining: 30.1s\n",
      "572:\tlearn: 0.0380807\ttotal: 40.3s\tremaining: 30s\n",
      "573:\tlearn: 0.0380710\ttotal: 40.4s\tremaining: 30s\n",
      "574:\tlearn: 0.0380557\ttotal: 40.4s\tremaining: 29.9s\n",
      "575:\tlearn: 0.0380425\ttotal: 40.5s\tremaining: 29.8s\n",
      "576:\tlearn: 0.0380293\ttotal: 40.6s\tremaining: 29.8s\n",
      "577:\tlearn: 0.0380188\ttotal: 40.7s\tremaining: 29.7s\n",
      "578:\tlearn: 0.0380061\ttotal: 40.7s\tremaining: 29.6s\n",
      "579:\tlearn: 0.0380008\ttotal: 40.8s\tremaining: 29.5s\n",
      "580:\tlearn: 0.0379877\ttotal: 40.9s\tremaining: 29.5s\n",
      "581:\tlearn: 0.0379743\ttotal: 40.9s\tremaining: 29.4s\n",
      "582:\tlearn: 0.0379602\ttotal: 41s\tremaining: 29.3s\n",
      "583:\tlearn: 0.0379518\ttotal: 41s\tremaining: 29.2s\n",
      "584:\tlearn: 0.0379465\ttotal: 41.1s\tremaining: 29.2s\n",
      "585:\tlearn: 0.0379364\ttotal: 41.2s\tremaining: 29.1s\n",
      "586:\tlearn: 0.0379286\ttotal: 41.2s\tremaining: 29s\n",
      "587:\tlearn: 0.0379180\ttotal: 41.3s\tremaining: 29s\n",
      "588:\tlearn: 0.0379019\ttotal: 41.4s\tremaining: 28.9s\n",
      "589:\tlearn: 0.0378985\ttotal: 41.5s\tremaining: 28.8s\n",
      "590:\tlearn: 0.0378885\ttotal: 41.5s\tremaining: 28.8s\n",
      "591:\tlearn: 0.0378769\ttotal: 41.6s\tremaining: 28.7s\n",
      "592:\tlearn: 0.0378661\ttotal: 41.7s\tremaining: 28.6s\n",
      "593:\tlearn: 0.0378554\ttotal: 41.8s\tremaining: 28.5s\n",
      "594:\tlearn: 0.0378459\ttotal: 41.8s\tremaining: 28.5s\n",
      "595:\tlearn: 0.0378365\ttotal: 41.9s\tremaining: 28.4s\n",
      "596:\tlearn: 0.0378319\ttotal: 42s\tremaining: 28.3s\n",
      "597:\tlearn: 0.0378239\ttotal: 42s\tremaining: 28.2s\n",
      "598:\tlearn: 0.0378130\ttotal: 42.1s\tremaining: 28.2s\n",
      "599:\tlearn: 0.0378037\ttotal: 42.2s\tremaining: 28.1s\n",
      "600:\tlearn: 0.0377842\ttotal: 42.3s\tremaining: 28.1s\n",
      "601:\tlearn: 0.0377699\ttotal: 42.3s\tremaining: 28s\n",
      "602:\tlearn: 0.0377570\ttotal: 42.4s\tremaining: 27.9s\n",
      "603:\tlearn: 0.0377473\ttotal: 42.5s\tremaining: 27.9s\n",
      "604:\tlearn: 0.0377388\ttotal: 42.6s\tremaining: 27.8s\n",
      "605:\tlearn: 0.0377264\ttotal: 42.6s\tremaining: 27.7s\n",
      "606:\tlearn: 0.0377164\ttotal: 42.7s\tremaining: 27.7s\n",
      "607:\tlearn: 0.0377077\ttotal: 42.8s\tremaining: 27.6s\n",
      "608:\tlearn: 0.0376959\ttotal: 42.9s\tremaining: 27.5s\n",
      "609:\tlearn: 0.0376895\ttotal: 43s\tremaining: 27.5s\n",
      "610:\tlearn: 0.0376792\ttotal: 43s\tremaining: 27.4s\n",
      "611:\tlearn: 0.0376650\ttotal: 43.1s\tremaining: 27.3s\n",
      "612:\tlearn: 0.0376572\ttotal: 43.2s\tremaining: 27.3s\n",
      "613:\tlearn: 0.0376496\ttotal: 43.3s\tremaining: 27.2s\n",
      "614:\tlearn: 0.0376465\ttotal: 43.3s\tremaining: 27.1s\n",
      "615:\tlearn: 0.0376347\ttotal: 43.4s\tremaining: 27.1s\n",
      "616:\tlearn: 0.0376220\ttotal: 43.5s\tremaining: 27s\n",
      "617:\tlearn: 0.0376044\ttotal: 43.6s\tremaining: 26.9s\n",
      "618:\tlearn: 0.0375955\ttotal: 43.7s\tremaining: 26.9s\n",
      "619:\tlearn: 0.0375814\ttotal: 43.7s\tremaining: 26.8s\n",
      "620:\tlearn: 0.0375744\ttotal: 43.8s\tremaining: 26.7s\n",
      "621:\tlearn: 0.0375579\ttotal: 43.9s\tremaining: 26.7s\n",
      "622:\tlearn: 0.0375471\ttotal: 44s\tremaining: 26.6s\n",
      "623:\tlearn: 0.0375420\ttotal: 44s\tremaining: 26.5s\n",
      "624:\tlearn: 0.0375306\ttotal: 44.1s\tremaining: 26.5s\n",
      "625:\tlearn: 0.0375149\ttotal: 44.2s\tremaining: 26.4s\n",
      "626:\tlearn: 0.0375004\ttotal: 44.3s\tremaining: 26.3s\n",
      "627:\tlearn: 0.0374938\ttotal: 44.4s\tremaining: 26.3s\n",
      "628:\tlearn: 0.0374935\ttotal: 44.4s\tremaining: 26.2s\n",
      "629:\tlearn: 0.0374813\ttotal: 44.5s\tremaining: 26.1s\n",
      "630:\tlearn: 0.0374730\ttotal: 44.6s\tremaining: 26.1s\n",
      "631:\tlearn: 0.0374637\ttotal: 44.6s\tremaining: 26s\n",
      "632:\tlearn: 0.0374514\ttotal: 44.7s\tremaining: 25.9s\n",
      "633:\tlearn: 0.0374413\ttotal: 44.8s\tremaining: 25.8s\n",
      "634:\tlearn: 0.0374412\ttotal: 44.8s\tremaining: 25.8s\n",
      "635:\tlearn: 0.0374319\ttotal: 44.9s\tremaining: 25.7s\n",
      "636:\tlearn: 0.0374198\ttotal: 45s\tremaining: 25.7s\n",
      "637:\tlearn: 0.0374138\ttotal: 45.1s\tremaining: 25.6s\n",
      "638:\tlearn: 0.0374040\ttotal: 45.2s\tremaining: 25.5s\n",
      "639:\tlearn: 0.0373949\ttotal: 45.2s\tremaining: 25.4s\n",
      "640:\tlearn: 0.0373853\ttotal: 45.3s\tremaining: 25.4s\n",
      "641:\tlearn: 0.0373746\ttotal: 45.4s\tremaining: 25.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642:\tlearn: 0.0373679\ttotal: 45.5s\tremaining: 25.2s\n",
      "643:\tlearn: 0.0373524\ttotal: 45.5s\tremaining: 25.2s\n",
      "644:\tlearn: 0.0373407\ttotal: 45.6s\tremaining: 25.1s\n",
      "645:\tlearn: 0.0373327\ttotal: 45.7s\tremaining: 25s\n",
      "646:\tlearn: 0.0373234\ttotal: 45.8s\tremaining: 25s\n",
      "647:\tlearn: 0.0373086\ttotal: 45.8s\tremaining: 24.9s\n",
      "648:\tlearn: 0.0372992\ttotal: 45.9s\tremaining: 24.8s\n",
      "649:\tlearn: 0.0372921\ttotal: 46s\tremaining: 24.8s\n",
      "650:\tlearn: 0.0372811\ttotal: 46s\tremaining: 24.7s\n",
      "651:\tlearn: 0.0372809\ttotal: 46.1s\tremaining: 24.6s\n",
      "652:\tlearn: 0.0372660\ttotal: 46.2s\tremaining: 24.5s\n",
      "653:\tlearn: 0.0372599\ttotal: 46.2s\tremaining: 24.5s\n",
      "654:\tlearn: 0.0372529\ttotal: 46.3s\tremaining: 24.4s\n",
      "655:\tlearn: 0.0372428\ttotal: 46.4s\tremaining: 24.3s\n",
      "656:\tlearn: 0.0372361\ttotal: 46.4s\tremaining: 24.2s\n",
      "657:\tlearn: 0.0372172\ttotal: 46.5s\tremaining: 24.2s\n",
      "658:\tlearn: 0.0372075\ttotal: 46.6s\tremaining: 24.1s\n",
      "659:\tlearn: 0.0371953\ttotal: 46.7s\tremaining: 24s\n",
      "660:\tlearn: 0.0371865\ttotal: 46.8s\tremaining: 24s\n",
      "661:\tlearn: 0.0371771\ttotal: 46.8s\tremaining: 23.9s\n",
      "662:\tlearn: 0.0371693\ttotal: 46.9s\tremaining: 23.8s\n",
      "663:\tlearn: 0.0371621\ttotal: 47s\tremaining: 23.8s\n",
      "664:\tlearn: 0.0371494\ttotal: 47.1s\tremaining: 23.7s\n",
      "665:\tlearn: 0.0371382\ttotal: 47.1s\tremaining: 23.6s\n",
      "666:\tlearn: 0.0371286\ttotal: 47.2s\tremaining: 23.6s\n",
      "667:\tlearn: 0.0371195\ttotal: 47.3s\tremaining: 23.5s\n",
      "668:\tlearn: 0.0371056\ttotal: 47.4s\tremaining: 23.4s\n",
      "669:\tlearn: 0.0370921\ttotal: 47.5s\tremaining: 23.4s\n",
      "670:\tlearn: 0.0370855\ttotal: 47.5s\tremaining: 23.3s\n",
      "671:\tlearn: 0.0370782\ttotal: 47.6s\tremaining: 23.2s\n",
      "672:\tlearn: 0.0370715\ttotal: 47.7s\tremaining: 23.2s\n",
      "673:\tlearn: 0.0370629\ttotal: 47.7s\tremaining: 23.1s\n",
      "674:\tlearn: 0.0370555\ttotal: 47.8s\tremaining: 23s\n",
      "675:\tlearn: 0.0370443\ttotal: 47.9s\tremaining: 23s\n",
      "676:\tlearn: 0.0370370\ttotal: 48s\tremaining: 22.9s\n",
      "677:\tlearn: 0.0370368\ttotal: 48s\tremaining: 22.8s\n",
      "678:\tlearn: 0.0370255\ttotal: 48.1s\tremaining: 22.7s\n",
      "679:\tlearn: 0.0370135\ttotal: 48.2s\tremaining: 22.7s\n",
      "680:\tlearn: 0.0369999\ttotal: 48.3s\tremaining: 22.6s\n",
      "681:\tlearn: 0.0369899\ttotal: 48.3s\tremaining: 22.5s\n",
      "682:\tlearn: 0.0369863\ttotal: 48.4s\tremaining: 22.5s\n",
      "683:\tlearn: 0.0369801\ttotal: 48.5s\tremaining: 22.4s\n",
      "684:\tlearn: 0.0369708\ttotal: 48.5s\tremaining: 22.3s\n",
      "685:\tlearn: 0.0369622\ttotal: 48.6s\tremaining: 22.2s\n",
      "686:\tlearn: 0.0369522\ttotal: 48.7s\tremaining: 22.2s\n",
      "687:\tlearn: 0.0369450\ttotal: 48.7s\tremaining: 22.1s\n",
      "688:\tlearn: 0.0369371\ttotal: 48.8s\tremaining: 22s\n",
      "689:\tlearn: 0.0369229\ttotal: 48.9s\tremaining: 22s\n",
      "690:\tlearn: 0.0369147\ttotal: 49s\tremaining: 21.9s\n",
      "691:\tlearn: 0.0369057\ttotal: 49s\tremaining: 21.8s\n",
      "692:\tlearn: 0.0368992\ttotal: 49.1s\tremaining: 21.7s\n",
      "693:\tlearn: 0.0368867\ttotal: 49.2s\tremaining: 21.7s\n",
      "694:\tlearn: 0.0368764\ttotal: 49.2s\tremaining: 21.6s\n",
      "695:\tlearn: 0.0368685\ttotal: 49.3s\tremaining: 21.5s\n",
      "696:\tlearn: 0.0368511\ttotal: 49.4s\tremaining: 21.5s\n",
      "697:\tlearn: 0.0368385\ttotal: 49.5s\tremaining: 21.4s\n",
      "698:\tlearn: 0.0368317\ttotal: 49.5s\tremaining: 21.3s\n",
      "699:\tlearn: 0.0368236\ttotal: 49.6s\tremaining: 21.3s\n",
      "700:\tlearn: 0.0368155\ttotal: 49.7s\tremaining: 21.2s\n",
      "701:\tlearn: 0.0368046\ttotal: 49.7s\tremaining: 21.1s\n",
      "702:\tlearn: 0.0367981\ttotal: 49.8s\tremaining: 21s\n",
      "703:\tlearn: 0.0367888\ttotal: 49.9s\tremaining: 21s\n",
      "704:\tlearn: 0.0367783\ttotal: 50s\tremaining: 20.9s\n",
      "705:\tlearn: 0.0367655\ttotal: 50s\tremaining: 20.8s\n",
      "706:\tlearn: 0.0367556\ttotal: 50.1s\tremaining: 20.8s\n",
      "707:\tlearn: 0.0367437\ttotal: 50.2s\tremaining: 20.7s\n",
      "708:\tlearn: 0.0367367\ttotal: 50.3s\tremaining: 20.6s\n",
      "709:\tlearn: 0.0367326\ttotal: 50.3s\tremaining: 20.6s\n",
      "710:\tlearn: 0.0367235\ttotal: 50.4s\tremaining: 20.5s\n",
      "711:\tlearn: 0.0367195\ttotal: 50.5s\tremaining: 20.4s\n",
      "712:\tlearn: 0.0367069\ttotal: 50.5s\tremaining: 20.3s\n",
      "713:\tlearn: 0.0366980\ttotal: 50.6s\tremaining: 20.3s\n",
      "714:\tlearn: 0.0366929\ttotal: 50.7s\tremaining: 20.2s\n",
      "715:\tlearn: 0.0366784\ttotal: 50.7s\tremaining: 20.1s\n",
      "716:\tlearn: 0.0366752\ttotal: 50.8s\tremaining: 20s\n",
      "717:\tlearn: 0.0366640\ttotal: 50.9s\tremaining: 20s\n",
      "718:\tlearn: 0.0366559\ttotal: 51s\tremaining: 19.9s\n",
      "719:\tlearn: 0.0366501\ttotal: 51s\tremaining: 19.8s\n",
      "720:\tlearn: 0.0366421\ttotal: 51.1s\tremaining: 19.8s\n",
      "721:\tlearn: 0.0366358\ttotal: 51.2s\tremaining: 19.7s\n",
      "722:\tlearn: 0.0366247\ttotal: 51.2s\tremaining: 19.6s\n",
      "723:\tlearn: 0.0366134\ttotal: 51.3s\tremaining: 19.6s\n",
      "724:\tlearn: 0.0365996\ttotal: 51.4s\tremaining: 19.5s\n",
      "725:\tlearn: 0.0365924\ttotal: 51.4s\tremaining: 19.4s\n",
      "726:\tlearn: 0.0365842\ttotal: 51.5s\tremaining: 19.3s\n",
      "727:\tlearn: 0.0365759\ttotal: 51.6s\tremaining: 19.3s\n",
      "728:\tlearn: 0.0365620\ttotal: 51.6s\tremaining: 19.2s\n",
      "729:\tlearn: 0.0365587\ttotal: 51.7s\tremaining: 19.1s\n",
      "730:\tlearn: 0.0365480\ttotal: 51.8s\tremaining: 19.1s\n",
      "731:\tlearn: 0.0365420\ttotal: 51.9s\tremaining: 19s\n",
      "732:\tlearn: 0.0365312\ttotal: 51.9s\tremaining: 18.9s\n",
      "733:\tlearn: 0.0365188\ttotal: 52s\tremaining: 18.9s\n",
      "734:\tlearn: 0.0365106\ttotal: 52.1s\tremaining: 18.8s\n",
      "735:\tlearn: 0.0364976\ttotal: 52.2s\tremaining: 18.7s\n",
      "736:\tlearn: 0.0364975\ttotal: 52.2s\tremaining: 18.6s\n",
      "737:\tlearn: 0.0364874\ttotal: 52.3s\tremaining: 18.6s\n",
      "738:\tlearn: 0.0364810\ttotal: 52.4s\tremaining: 18.5s\n",
      "739:\tlearn: 0.0364728\ttotal: 52.4s\tremaining: 18.4s\n",
      "740:\tlearn: 0.0364679\ttotal: 52.5s\tremaining: 18.4s\n",
      "741:\tlearn: 0.0364585\ttotal: 52.6s\tremaining: 18.3s\n",
      "742:\tlearn: 0.0364470\ttotal: 52.7s\tremaining: 18.2s\n",
      "743:\tlearn: 0.0364293\ttotal: 52.8s\tremaining: 18.2s\n",
      "744:\tlearn: 0.0364231\ttotal: 52.8s\tremaining: 18.1s\n",
      "745:\tlearn: 0.0364090\ttotal: 52.9s\tremaining: 18s\n",
      "746:\tlearn: 0.0364035\ttotal: 53s\tremaining: 17.9s\n",
      "747:\tlearn: 0.0363980\ttotal: 53.1s\tremaining: 17.9s\n",
      "748:\tlearn: 0.0363880\ttotal: 53.1s\tremaining: 17.8s\n",
      "749:\tlearn: 0.0363835\ttotal: 53.2s\tremaining: 17.7s\n",
      "750:\tlearn: 0.0363698\ttotal: 53.3s\tremaining: 17.7s\n",
      "751:\tlearn: 0.0363696\ttotal: 53.3s\tremaining: 17.6s\n",
      "752:\tlearn: 0.0363552\ttotal: 53.4s\tremaining: 17.5s\n",
      "753:\tlearn: 0.0363473\ttotal: 53.5s\tremaining: 17.5s\n",
      "754:\tlearn: 0.0363414\ttotal: 53.6s\tremaining: 17.4s\n",
      "755:\tlearn: 0.0363271\ttotal: 53.6s\tremaining: 17.3s\n",
      "756:\tlearn: 0.0363269\ttotal: 53.7s\tremaining: 17.2s\n",
      "757:\tlearn: 0.0363154\ttotal: 53.8s\tremaining: 17.2s\n",
      "758:\tlearn: 0.0363067\ttotal: 53.9s\tremaining: 17.1s\n",
      "759:\tlearn: 0.0363033\ttotal: 53.9s\tremaining: 17s\n",
      "760:\tlearn: 0.0362920\ttotal: 54s\tremaining: 17s\n",
      "761:\tlearn: 0.0362863\ttotal: 54.1s\tremaining: 16.9s\n",
      "762:\tlearn: 0.0362838\ttotal: 54.2s\tremaining: 16.8s\n",
      "763:\tlearn: 0.0362787\ttotal: 54.2s\tremaining: 16.7s\n",
      "764:\tlearn: 0.0362663\ttotal: 54.3s\tremaining: 16.7s\n",
      "765:\tlearn: 0.0362661\ttotal: 54.4s\tremaining: 16.6s\n",
      "766:\tlearn: 0.0362586\ttotal: 54.4s\tremaining: 16.5s\n",
      "767:\tlearn: 0.0362456\ttotal: 54.5s\tremaining: 16.5s\n",
      "768:\tlearn: 0.0362351\ttotal: 54.6s\tremaining: 16.4s\n",
      "769:\tlearn: 0.0362267\ttotal: 54.7s\tremaining: 16.3s\n",
      "770:\tlearn: 0.0362146\ttotal: 54.8s\tremaining: 16.3s\n",
      "771:\tlearn: 0.0362057\ttotal: 54.8s\tremaining: 16.2s\n",
      "772:\tlearn: 0.0361945\ttotal: 54.9s\tremaining: 16.1s\n",
      "773:\tlearn: 0.0361899\ttotal: 55s\tremaining: 16.1s\n",
      "774:\tlearn: 0.0361842\ttotal: 55s\tremaining: 16s\n",
      "775:\tlearn: 0.0361841\ttotal: 55.1s\tremaining: 15.9s\n",
      "776:\tlearn: 0.0361731\ttotal: 55.2s\tremaining: 15.8s\n",
      "777:\tlearn: 0.0361672\ttotal: 55.2s\tremaining: 15.8s\n",
      "778:\tlearn: 0.0361581\ttotal: 55.3s\tremaining: 15.7s\n",
      "779:\tlearn: 0.0361456\ttotal: 55.4s\tremaining: 15.6s\n",
      "780:\tlearn: 0.0361384\ttotal: 55.5s\tremaining: 15.6s\n",
      "781:\tlearn: 0.0361348\ttotal: 55.5s\tremaining: 15.5s\n",
      "782:\tlearn: 0.0361253\ttotal: 55.6s\tremaining: 15.4s\n",
      "783:\tlearn: 0.0361167\ttotal: 55.7s\tremaining: 15.3s\n",
      "784:\tlearn: 0.0361103\ttotal: 55.8s\tremaining: 15.3s\n",
      "785:\tlearn: 0.0361079\ttotal: 55.8s\tremaining: 15.2s\n",
      "786:\tlearn: 0.0360984\ttotal: 55.9s\tremaining: 15.1s\n",
      "787:\tlearn: 0.0360865\ttotal: 56s\tremaining: 15.1s\n",
      "788:\tlearn: 0.0360861\ttotal: 56.1s\tremaining: 15s\n",
      "789:\tlearn: 0.0360775\ttotal: 56.2s\tremaining: 14.9s\n",
      "790:\tlearn: 0.0360694\ttotal: 56.2s\tremaining: 14.9s\n",
      "791:\tlearn: 0.0360606\ttotal: 56.3s\tremaining: 14.8s\n",
      "792:\tlearn: 0.0360499\ttotal: 56.4s\tremaining: 14.7s\n",
      "793:\tlearn: 0.0360444\ttotal: 56.4s\tremaining: 14.6s\n",
      "794:\tlearn: 0.0360366\ttotal: 56.5s\tremaining: 14.6s\n",
      "795:\tlearn: 0.0360319\ttotal: 56.6s\tremaining: 14.5s\n",
      "796:\tlearn: 0.0360184\ttotal: 56.6s\tremaining: 14.4s\n",
      "797:\tlearn: 0.0360087\ttotal: 56.7s\tremaining: 14.4s\n",
      "798:\tlearn: 0.0359993\ttotal: 56.8s\tremaining: 14.3s\n",
      "799:\tlearn: 0.0359971\ttotal: 56.8s\tremaining: 14.2s\n",
      "800:\tlearn: 0.0359965\ttotal: 56.9s\tremaining: 14.1s\n",
      "801:\tlearn: 0.0359887\ttotal: 57s\tremaining: 14.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802:\tlearn: 0.0359777\ttotal: 57s\tremaining: 14s\n",
      "803:\tlearn: 0.0359752\ttotal: 57.1s\tremaining: 13.9s\n",
      "804:\tlearn: 0.0359638\ttotal: 57.2s\tremaining: 13.8s\n",
      "805:\tlearn: 0.0359584\ttotal: 57.2s\tremaining: 13.8s\n",
      "806:\tlearn: 0.0359514\ttotal: 57.3s\tremaining: 13.7s\n",
      "807:\tlearn: 0.0359511\ttotal: 57.3s\tremaining: 13.6s\n",
      "808:\tlearn: 0.0359451\ttotal: 57.4s\tremaining: 13.6s\n",
      "809:\tlearn: 0.0359348\ttotal: 57.5s\tremaining: 13.5s\n",
      "810:\tlearn: 0.0359347\ttotal: 57.5s\tremaining: 13.4s\n",
      "811:\tlearn: 0.0359252\ttotal: 57.6s\tremaining: 13.3s\n",
      "812:\tlearn: 0.0359195\ttotal: 57.7s\tremaining: 13.3s\n",
      "813:\tlearn: 0.0359191\ttotal: 57.7s\tremaining: 13.2s\n",
      "814:\tlearn: 0.0359111\ttotal: 57.8s\tremaining: 13.1s\n",
      "815:\tlearn: 0.0359058\ttotal: 57.9s\tremaining: 13.1s\n",
      "816:\tlearn: 0.0359057\ttotal: 57.9s\tremaining: 13s\n",
      "817:\tlearn: 0.0358992\ttotal: 58s\tremaining: 12.9s\n",
      "818:\tlearn: 0.0358954\ttotal: 58.1s\tremaining: 12.8s\n",
      "819:\tlearn: 0.0358871\ttotal: 58.1s\tremaining: 12.8s\n",
      "820:\tlearn: 0.0358816\ttotal: 58.2s\tremaining: 12.7s\n",
      "821:\tlearn: 0.0358742\ttotal: 58.3s\tremaining: 12.6s\n",
      "822:\tlearn: 0.0358680\ttotal: 58.3s\tremaining: 12.5s\n",
      "823:\tlearn: 0.0358679\ttotal: 58.4s\tremaining: 12.5s\n",
      "824:\tlearn: 0.0358636\ttotal: 58.5s\tremaining: 12.4s\n",
      "825:\tlearn: 0.0358631\ttotal: 58.5s\tremaining: 12.3s\n",
      "826:\tlearn: 0.0358510\ttotal: 58.6s\tremaining: 12.3s\n",
      "827:\tlearn: 0.0358509\ttotal: 58.6s\tremaining: 12.2s\n",
      "828:\tlearn: 0.0358477\ttotal: 58.7s\tremaining: 12.1s\n",
      "829:\tlearn: 0.0358425\ttotal: 58.8s\tremaining: 12s\n",
      "830:\tlearn: 0.0358424\ttotal: 58.8s\tremaining: 12s\n",
      "831:\tlearn: 0.0358395\ttotal: 58.9s\tremaining: 11.9s\n",
      "832:\tlearn: 0.0358392\ttotal: 58.9s\tremaining: 11.8s\n",
      "833:\tlearn: 0.0358238\ttotal: 59s\tremaining: 11.7s\n",
      "834:\tlearn: 0.0358159\ttotal: 59.1s\tremaining: 11.7s\n",
      "835:\tlearn: 0.0358154\ttotal: 59.1s\tremaining: 11.6s\n",
      "836:\tlearn: 0.0358036\ttotal: 59.2s\tremaining: 11.5s\n",
      "837:\tlearn: 0.0357923\ttotal: 59.3s\tremaining: 11.5s\n",
      "838:\tlearn: 0.0357871\ttotal: 59.3s\tremaining: 11.4s\n",
      "839:\tlearn: 0.0357735\ttotal: 59.4s\tremaining: 11.3s\n",
      "840:\tlearn: 0.0357681\ttotal: 59.5s\tremaining: 11.2s\n",
      "841:\tlearn: 0.0357598\ttotal: 59.6s\tremaining: 11.2s\n",
      "842:\tlearn: 0.0357515\ttotal: 59.6s\tremaining: 11.1s\n",
      "843:\tlearn: 0.0357470\ttotal: 59.7s\tremaining: 11s\n",
      "844:\tlearn: 0.0357430\ttotal: 59.8s\tremaining: 11s\n",
      "845:\tlearn: 0.0357363\ttotal: 59.8s\tremaining: 10.9s\n",
      "846:\tlearn: 0.0357287\ttotal: 59.9s\tremaining: 10.8s\n",
      "847:\tlearn: 0.0357180\ttotal: 1m\tremaining: 10.8s\n",
      "848:\tlearn: 0.0357095\ttotal: 1m\tremaining: 10.7s\n",
      "849:\tlearn: 0.0357042\ttotal: 1m\tremaining: 10.6s\n",
      "850:\tlearn: 0.0356942\ttotal: 1m\tremaining: 10.5s\n",
      "851:\tlearn: 0.0356823\ttotal: 1m\tremaining: 10.5s\n",
      "852:\tlearn: 0.0356788\ttotal: 1m\tremaining: 10.4s\n",
      "853:\tlearn: 0.0356756\ttotal: 1m\tremaining: 10.3s\n",
      "854:\tlearn: 0.0356755\ttotal: 1m\tremaining: 10.3s\n",
      "855:\tlearn: 0.0356665\ttotal: 1m\tremaining: 10.2s\n",
      "856:\tlearn: 0.0356570\ttotal: 1m\tremaining: 10.1s\n",
      "857:\tlearn: 0.0356457\ttotal: 1m\tremaining: 10s\n",
      "858:\tlearn: 0.0356433\ttotal: 1m\tremaining: 9.97s\n",
      "859:\tlearn: 0.0356323\ttotal: 1m\tremaining: 9.9s\n",
      "860:\tlearn: 0.0356272\ttotal: 1m\tremaining: 9.82s\n",
      "861:\tlearn: 0.0356194\ttotal: 1m\tremaining: 9.75s\n",
      "862:\tlearn: 0.0356186\ttotal: 1m\tremaining: 9.68s\n",
      "863:\tlearn: 0.0356154\ttotal: 1m 1s\tremaining: 9.61s\n",
      "864:\tlearn: 0.0356153\ttotal: 1m 1s\tremaining: 9.53s\n",
      "865:\tlearn: 0.0356033\ttotal: 1m 1s\tremaining: 9.46s\n",
      "866:\tlearn: 0.0355926\ttotal: 1m 1s\tremaining: 9.39s\n",
      "867:\tlearn: 0.0355834\ttotal: 1m 1s\tremaining: 9.32s\n",
      "868:\tlearn: 0.0355832\ttotal: 1m 1s\tremaining: 9.25s\n",
      "869:\tlearn: 0.0355769\ttotal: 1m 1s\tremaining: 9.18s\n",
      "870:\tlearn: 0.0355761\ttotal: 1m 1s\tremaining: 9.11s\n",
      "871:\tlearn: 0.0355615\ttotal: 1m 1s\tremaining: 9.04s\n",
      "872:\tlearn: 0.0355547\ttotal: 1m 1s\tremaining: 8.96s\n",
      "873:\tlearn: 0.0355497\ttotal: 1m 1s\tremaining: 8.89s\n",
      "874:\tlearn: 0.0355398\ttotal: 1m 1s\tremaining: 8.82s\n",
      "875:\tlearn: 0.0355291\ttotal: 1m 1s\tremaining: 8.75s\n",
      "876:\tlearn: 0.0355272\ttotal: 1m 1s\tremaining: 8.68s\n",
      "877:\tlearn: 0.0355270\ttotal: 1m 1s\tremaining: 8.61s\n",
      "878:\tlearn: 0.0355174\ttotal: 1m 2s\tremaining: 8.54s\n",
      "879:\tlearn: 0.0355122\ttotal: 1m 2s\tremaining: 8.46s\n",
      "880:\tlearn: 0.0355056\ttotal: 1m 2s\tremaining: 8.39s\n",
      "881:\tlearn: 0.0355031\ttotal: 1m 2s\tremaining: 8.32s\n",
      "882:\tlearn: 0.0354973\ttotal: 1m 2s\tremaining: 8.25s\n",
      "883:\tlearn: 0.0354918\ttotal: 1m 2s\tremaining: 8.18s\n",
      "884:\tlearn: 0.0354815\ttotal: 1m 2s\tremaining: 8.11s\n",
      "885:\tlearn: 0.0354775\ttotal: 1m 2s\tremaining: 8.04s\n",
      "886:\tlearn: 0.0354774\ttotal: 1m 2s\tremaining: 7.96s\n",
      "887:\tlearn: 0.0354675\ttotal: 1m 2s\tremaining: 7.89s\n",
      "888:\tlearn: 0.0354561\ttotal: 1m 2s\tremaining: 7.83s\n",
      "889:\tlearn: 0.0354512\ttotal: 1m 2s\tremaining: 7.75s\n",
      "890:\tlearn: 0.0354431\ttotal: 1m 2s\tremaining: 7.68s\n",
      "891:\tlearn: 0.0354431\ttotal: 1m 2s\tremaining: 7.61s\n",
      "892:\tlearn: 0.0354375\ttotal: 1m 2s\tremaining: 7.54s\n",
      "893:\tlearn: 0.0354334\ttotal: 1m 3s\tremaining: 7.47s\n",
      "894:\tlearn: 0.0354333\ttotal: 1m 3s\tremaining: 7.4s\n",
      "895:\tlearn: 0.0354329\ttotal: 1m 3s\tremaining: 7.33s\n",
      "896:\tlearn: 0.0354327\ttotal: 1m 3s\tremaining: 7.25s\n",
      "897:\tlearn: 0.0354204\ttotal: 1m 3s\tremaining: 7.18s\n",
      "898:\tlearn: 0.0354183\ttotal: 1m 3s\tremaining: 7.11s\n",
      "899:\tlearn: 0.0354096\ttotal: 1m 3s\tremaining: 7.04s\n",
      "900:\tlearn: 0.0353994\ttotal: 1m 3s\tremaining: 6.97s\n",
      "901:\tlearn: 0.0353897\ttotal: 1m 3s\tremaining: 6.9s\n",
      "902:\tlearn: 0.0353807\ttotal: 1m 3s\tremaining: 6.83s\n",
      "903:\tlearn: 0.0353769\ttotal: 1m 3s\tremaining: 6.76s\n",
      "904:\tlearn: 0.0353668\ttotal: 1m 3s\tremaining: 6.69s\n",
      "905:\tlearn: 0.0353597\ttotal: 1m 3s\tremaining: 6.62s\n",
      "906:\tlearn: 0.0353570\ttotal: 1m 3s\tremaining: 6.54s\n",
      "907:\tlearn: 0.0353520\ttotal: 1m 3s\tremaining: 6.47s\n",
      "908:\tlearn: 0.0353519\ttotal: 1m 3s\tremaining: 6.4s\n",
      "909:\tlearn: 0.0353458\ttotal: 1m 4s\tremaining: 6.33s\n",
      "910:\tlearn: 0.0353457\ttotal: 1m 4s\tremaining: 6.26s\n",
      "911:\tlearn: 0.0353322\ttotal: 1m 4s\tremaining: 6.19s\n",
      "912:\tlearn: 0.0353270\ttotal: 1m 4s\tremaining: 6.12s\n",
      "913:\tlearn: 0.0353188\ttotal: 1m 4s\tremaining: 6.05s\n",
      "914:\tlearn: 0.0353159\ttotal: 1m 4s\tremaining: 5.97s\n",
      "915:\tlearn: 0.0353156\ttotal: 1m 4s\tremaining: 5.9s\n",
      "916:\tlearn: 0.0353050\ttotal: 1m 4s\tremaining: 5.83s\n",
      "917:\tlearn: 0.0352971\ttotal: 1m 4s\tremaining: 5.76s\n",
      "918:\tlearn: 0.0352892\ttotal: 1m 4s\tremaining: 5.69s\n",
      "919:\tlearn: 0.0352803\ttotal: 1m 4s\tremaining: 5.62s\n",
      "920:\tlearn: 0.0352715\ttotal: 1m 4s\tremaining: 5.55s\n",
      "921:\tlearn: 0.0352658\ttotal: 1m 4s\tremaining: 5.48s\n",
      "922:\tlearn: 0.0352560\ttotal: 1m 4s\tremaining: 5.41s\n",
      "923:\tlearn: 0.0352523\ttotal: 1m 4s\tremaining: 5.34s\n",
      "924:\tlearn: 0.0352437\ttotal: 1m 4s\tremaining: 5.27s\n",
      "925:\tlearn: 0.0352402\ttotal: 1m 5s\tremaining: 5.2s\n",
      "926:\tlearn: 0.0352305\ttotal: 1m 5s\tremaining: 5.13s\n",
      "927:\tlearn: 0.0352244\ttotal: 1m 5s\tremaining: 5.06s\n",
      "928:\tlearn: 0.0352189\ttotal: 1m 5s\tremaining: 4.99s\n",
      "929:\tlearn: 0.0352076\ttotal: 1m 5s\tremaining: 4.92s\n",
      "930:\tlearn: 0.0351993\ttotal: 1m 5s\tremaining: 4.85s\n",
      "931:\tlearn: 0.0351974\ttotal: 1m 5s\tremaining: 4.78s\n",
      "932:\tlearn: 0.0351913\ttotal: 1m 5s\tremaining: 4.71s\n",
      "933:\tlearn: 0.0351823\ttotal: 1m 5s\tremaining: 4.63s\n",
      "934:\tlearn: 0.0351748\ttotal: 1m 5s\tremaining: 4.56s\n",
      "935:\tlearn: 0.0351617\ttotal: 1m 5s\tremaining: 4.49s\n",
      "936:\tlearn: 0.0351507\ttotal: 1m 5s\tremaining: 4.42s\n",
      "937:\tlearn: 0.0351433\ttotal: 1m 5s\tremaining: 4.35s\n",
      "938:\tlearn: 0.0351372\ttotal: 1m 5s\tremaining: 4.28s\n",
      "939:\tlearn: 0.0351328\ttotal: 1m 5s\tremaining: 4.21s\n",
      "940:\tlearn: 0.0351271\ttotal: 1m 6s\tremaining: 4.14s\n",
      "941:\tlearn: 0.0351163\ttotal: 1m 6s\tremaining: 4.07s\n",
      "942:\tlearn: 0.0351140\ttotal: 1m 6s\tremaining: 4s\n",
      "943:\tlearn: 0.0351047\ttotal: 1m 6s\tremaining: 3.93s\n",
      "944:\tlearn: 0.0351025\ttotal: 1m 6s\tremaining: 3.86s\n",
      "945:\tlearn: 0.0350981\ttotal: 1m 6s\tremaining: 3.79s\n",
      "946:\tlearn: 0.0350959\ttotal: 1m 6s\tremaining: 3.72s\n",
      "947:\tlearn: 0.0350866\ttotal: 1m 6s\tremaining: 3.65s\n",
      "948:\tlearn: 0.0350754\ttotal: 1m 6s\tremaining: 3.58s\n",
      "949:\tlearn: 0.0350595\ttotal: 1m 6s\tremaining: 3.51s\n",
      "950:\tlearn: 0.0350520\ttotal: 1m 6s\tremaining: 3.44s\n",
      "951:\tlearn: 0.0350501\ttotal: 1m 6s\tremaining: 3.37s\n",
      "952:\tlearn: 0.0350478\ttotal: 1m 6s\tremaining: 3.3s\n",
      "953:\tlearn: 0.0350448\ttotal: 1m 6s\tremaining: 3.23s\n",
      "954:\tlearn: 0.0350386\ttotal: 1m 6s\tremaining: 3.15s\n",
      "955:\tlearn: 0.0350337\ttotal: 1m 7s\tremaining: 3.08s\n",
      "956:\tlearn: 0.0350334\ttotal: 1m 7s\tremaining: 3.01s\n",
      "957:\tlearn: 0.0350307\ttotal: 1m 7s\tremaining: 2.94s\n",
      "958:\tlearn: 0.0350188\ttotal: 1m 7s\tremaining: 2.87s\n",
      "959:\tlearn: 0.0350182\ttotal: 1m 7s\tremaining: 2.8s\n",
      "960:\tlearn: 0.0350073\ttotal: 1m 7s\tremaining: 2.73s\n",
      "961:\tlearn: 0.0349982\ttotal: 1m 7s\tremaining: 2.66s\n",
      "962:\tlearn: 0.0349936\ttotal: 1m 7s\tremaining: 2.59s\n",
      "963:\tlearn: 0.0349864\ttotal: 1m 7s\tremaining: 2.52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964:\tlearn: 0.0349789\ttotal: 1m 7s\tremaining: 2.45s\n",
      "965:\tlearn: 0.0349741\ttotal: 1m 7s\tremaining: 2.38s\n",
      "966:\tlearn: 0.0349683\ttotal: 1m 7s\tremaining: 2.31s\n",
      "967:\tlearn: 0.0349656\ttotal: 1m 7s\tremaining: 2.24s\n",
      "968:\tlearn: 0.0349599\ttotal: 1m 7s\tremaining: 2.17s\n",
      "969:\tlearn: 0.0349597\ttotal: 1m 7s\tremaining: 2.1s\n",
      "970:\tlearn: 0.0349524\ttotal: 1m 7s\tremaining: 2.03s\n",
      "971:\tlearn: 0.0349456\ttotal: 1m 8s\tremaining: 1.96s\n",
      "972:\tlearn: 0.0349453\ttotal: 1m 8s\tremaining: 1.89s\n",
      "973:\tlearn: 0.0349387\ttotal: 1m 8s\tremaining: 1.82s\n",
      "974:\tlearn: 0.0349249\ttotal: 1m 8s\tremaining: 1.75s\n",
      "975:\tlearn: 0.0349212\ttotal: 1m 8s\tremaining: 1.68s\n",
      "976:\tlearn: 0.0349105\ttotal: 1m 8s\tremaining: 1.61s\n",
      "977:\tlearn: 0.0349051\ttotal: 1m 8s\tremaining: 1.54s\n",
      "978:\tlearn: 0.0348992\ttotal: 1m 8s\tremaining: 1.47s\n",
      "979:\tlearn: 0.0348957\ttotal: 1m 8s\tremaining: 1.4s\n",
      "980:\tlearn: 0.0348953\ttotal: 1m 8s\tremaining: 1.33s\n",
      "981:\tlearn: 0.0348946\ttotal: 1m 8s\tremaining: 1.26s\n",
      "982:\tlearn: 0.0348867\ttotal: 1m 8s\tremaining: 1.19s\n",
      "983:\tlearn: 0.0348848\ttotal: 1m 8s\tremaining: 1.12s\n",
      "984:\tlearn: 0.0348758\ttotal: 1m 8s\tremaining: 1.05s\n",
      "985:\tlearn: 0.0348715\ttotal: 1m 8s\tremaining: 980ms\n",
      "986:\tlearn: 0.0348708\ttotal: 1m 9s\tremaining: 909ms\n",
      "987:\tlearn: 0.0348612\ttotal: 1m 9s\tremaining: 840ms\n",
      "988:\tlearn: 0.0348611\ttotal: 1m 9s\tremaining: 769ms\n",
      "989:\tlearn: 0.0348568\ttotal: 1m 9s\tremaining: 699ms\n",
      "990:\tlearn: 0.0348500\ttotal: 1m 9s\tremaining: 629ms\n",
      "991:\tlearn: 0.0348427\ttotal: 1m 9s\tremaining: 559ms\n",
      "992:\tlearn: 0.0348390\ttotal: 1m 9s\tremaining: 489ms\n",
      "993:\tlearn: 0.0348366\ttotal: 1m 9s\tremaining: 419ms\n",
      "994:\tlearn: 0.0348309\ttotal: 1m 9s\tremaining: 350ms\n",
      "995:\tlearn: 0.0348201\ttotal: 1m 9s\tremaining: 280ms\n",
      "996:\tlearn: 0.0348137\ttotal: 1m 9s\tremaining: 210ms\n",
      "997:\tlearn: 0.0348084\ttotal: 1m 9s\tremaining: 140ms\n",
      "998:\tlearn: 0.0348027\ttotal: 1m 9s\tremaining: 69.9ms\n",
      "999:\tlearn: 0.0348002\ttotal: 1m 9s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x21f11967dc0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model = CatBoostClassifier(scale_pos_weight=1/11)\n",
    "cat_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f137e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cat = cat_model.predict_proba(X_test)[:,1] \n",
    "submission_cat = pd.DataFrame({\"ID_code\": test.iloc[:,0]})\n",
    "submission_cat[\"target\"] = y_pred_cat\n",
    "submission_cat.to_csv(\"submission_cat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc58f846",
   "metadata": {},
   "source": [
    "# SVC drop (too slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd279a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel=\"rbf\")#, gamma=0.1, C=1000)\n",
    "svc_model.fit(X_train,y_train)\n",
    "y_pred_svc = svc_model.predict_proba(test[features])[:,1] \n",
    "submission_svc = pd.DataFrame({\"ID_code\": test.iloc[:,0]})\n",
    "submission_svc[\"target\"] = y_pred_svc\n",
    "submission_svc.to_csv(\"submission_svc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63393d5",
   "metadata": {},
   "source": [
    "# Stacking 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "383d6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_1 = XGBClassifier(learning_rate=0.1,max_depth=5,scale_pos_weight=1/11,n_estimators=400)\n",
    "model_2 = LGBMClassifier(**{\n",
    "     'learning_rate': 0.04,\n",
    "     'num_leaves': 31,\n",
    "     'max_bin': 1023,\n",
    "     'min_child_samples': 1000,\n",
    "     'reg_alpha': 0.1,\n",
    "     'reg_lambda': 0.2,\n",
    "     'feature_fraction': 1.0,\n",
    "     'bagging_freq': 1,\n",
    "     'bagging_fraction': 0.85,\n",
    "     'objective': 'binary',\n",
    "     'n_jobs': -1,\n",
    "     'n_estimators':400})\n",
    "model_3 = SVC(kernel=\"rbf\", gamma=0.1, C=1000)\n",
    "model_4 = CatBoostClassifier(learning_rate=0.05,scale_pos_weight=1/11)\n",
    "\n",
    "# putting all base model objects in one list\n",
    "all_models = [('xgb', model_1), ('lgbm', model_2),('svc',model_3)]\n",
    " \n",
    "# create meta model\n",
    "final_lr = LogisticRegression(class_weight='balanced',\n",
    "                              solver='saga')\n",
    "\n",
    "# stacked model\n",
    "stack = StackingClassifier(estimators=all_models,\n",
    "                           final_estimator=final_lr,\n",
    "                           cv=None,\n",
    "                           stack_method='predict_proba',\n",
    "                           passthrough=True, # Train final model on predictions and base data\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "3eb8759f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yujun Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:12:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Yujun Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yujun Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yujun Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:17:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yujun Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:19:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yujun Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:21:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min finished\n",
      "C:\\Users\\Yujun Wang\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('xgb',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              gamma=None, gpu_id=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constra...\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None,\n",
       "                                              reg_alpha=None, reg_lambda=None,\n",
       "                                              scale_pos_weight=None,\n",
       "                                              subsample=None, tree_method=None,\n",
       "                                              validate_parameters=None,\n",
       "                                              verbosity=None)),\n",
       "                               ('lgbm', LGBMClassifier())],\n",
       "                   final_estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                      solver='saga'),\n",
       "                   passthrough=True, stack_method='predict_proba', verbose=1)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "75b4f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack = stack.predict_proba(test[features])[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "89da3c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission_stack = pd.DataFrame({\"ID_code\": test.iloc[:,0]})\n",
    "submission_stack[\"target\"] = y_pred_stack\n",
    "submission_stack.to_csv(\"submission_stack.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f6ea2",
   "metadata": {},
   "source": [
    "# LGBM Scale drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01c26fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standardization to features\n",
    "# Apply Scaling to X_train and X_test\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90124e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75166528,  0.24145398, -0.6563144 , ..., -1.13812123,\n",
       "         0.44822196,  1.6068841 ],\n",
       "       [ 0.18762057,  1.26171109,  1.41406922, ..., -1.73949474,\n",
       "         0.61577357, -1.57570455],\n",
       "       [-0.62386073,  0.34921302,  0.60623758, ...,  0.61452112,\n",
       "        -0.64109605,  0.25351976],\n",
       "       ...,\n",
       "       [-0.39869081,  0.65063244, -0.11673668, ..., -0.46565365,\n",
       "        -1.56302854,  1.34118324],\n",
       "       [-0.45781603,  0.76238804,  0.2503975 , ...,  0.93151832,\n",
       "         0.06246128, -0.61965906],\n",
       "       [-0.82745571, -0.24047664, -0.00978379, ..., -0.52146683,\n",
       "        -0.55878183,  1.01441615]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1dd7a0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "model_std=model.fit(X_train_std,y_train)\n",
    "# score: 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b12c38d9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yujun Wang\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_std=plot_roc_curve(model_std, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eddf524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "y_pred = model.predict_proba(test[features])[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2f3abbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_std = model_std.predict_proba(test[features])[:,1] \n",
    "submission_std = pd.DataFrame({\"ID_code\": test.iloc[:,0]})\n",
    "submission_std[\"target\"] = y_pred_std\n",
    "submission_std.to_csv(\"submission_std.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ca850864",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"ID_code\": test.iloc[:,0]})\n",
    "submission[\"target\"] = y_pred\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd231686",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0ea334c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking(input_shape=None):\n",
    "    '''A stacking model that consists of CatBoostRegressor,\n",
    "    XGBRegressor, a linear model, and some neural networks'''\n",
    "    # First we create a list called \"level0\", which consists of our base models\"\n",
    "    # These models will get passed down to the meta-learner later\n",
    "    level0 = list()\n",
    "    #level0.append(('cat', CatBoostRegressor(verbose=False)))\n",
    "    #level0.append(('cat2', CatBoostRegressor(verbose=False, learning_rate=.0001)))\n",
    "    level0.append(('xgb', XGBClassifier()))\n",
    "    level0.append(('xgb2', XGBClassifier(\n",
    "              base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.5,\n",
    "              enable_categorical=False, eval_metric='auc', gamma=0, gpu_id=-1,\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=5000, n_jobs=4, num_parallel_tree=1,\n",
    "              predictor='auto', random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "              scale_pos_weight=1, subsample=0.5, tree_method='exact',\n",
    "              validate_parameters=1, verbosity=1)))\n",
    "    level0.append(('lgbm',LGBMClassifier(**{\n",
    "     'learning_rate': 0.04,\n",
    "     'num_leaves': 31,\n",
    "     'max_bin': 1023,\n",
    "     'min_child_samples': 1000,\n",
    "     'reg_alpha': 0.1,\n",
    "     'reg_lambda': 0.2,\n",
    "     'feature_fraction': 1.0,\n",
    "     'bagging_freq': 1,\n",
    "     'bagging_fraction': 0.85,\n",
    "     'objective': 'binary',\n",
    "     'n_jobs': -1,\n",
    "     'n_estimators':400})))\n",
    "    N_units = 400\n",
    "    kernel_size=2\n",
    "    strides=2\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(N_units, kernel_size=kernel_size, strides=strides, padding='valid', \n",
    "                     activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(1, activation = 'sigmoid'))\n",
    "    epochs = 10\n",
    "    LR_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=2, factor=.5, min_lr=.0001)\n",
    "    EarlyStop_callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True)\n",
    "    my_callback=[EarlyStop_callback, LR_callback]\n",
    "    cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    level0.append(('nn_{num}'.format(num=i), cnn_model))\n",
    "    level1 =LogisticRegression()\n",
    "    # Create the stacking ensemble\n",
    "    model_stack = StackingClassifier(estimators=level0, final_estimator=level1,cv=2,verbose=1)\n",
    "    return model_stack\n",
    "#model_stack = get_stacking(400)\n",
    "#model_stack.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
