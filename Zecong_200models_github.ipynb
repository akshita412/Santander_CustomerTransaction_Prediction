{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6faf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ce4ff",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "052e085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99179366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7250a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 201)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15620dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = df_test['ID_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e304b14",
   "metadata": {},
   "source": [
    "## Find fake test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3bd16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for var in df_test.columns[1:]:\n",
    "    dict_count = df_test[var].value_counts().to_dict()\n",
    "    new_col = var + '_unique'\n",
    "    df_test[new_col] = df_test[var].apply(lambda s: 1 if dict_count[s]==1 else 0)\n",
    "df_test['has_unique'] = np.sum(df_test.iloc[:,201:],axis=1).apply(lambda s: 1 if s>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4982922c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100000\n",
       "1    100000\n",
       "Name: has_unique, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['has_unique'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2a9ef",
   "metadata": {},
   "source": [
    "* In test data, half of them are fake data, half are real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b210c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = df_test[df_test['has_unique']==1].iloc[:,:201]\n",
    "fake_test = df_test[df_test['has_unique']==0].iloc[:,:201]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518dd69c",
   "metadata": {},
   "source": [
    "## Combine train and read test data, then add new frequency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265ab37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_realtest = pd.concat([df_train, real_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3052f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for var in train_realtest.columns[2:]:\n",
    "    dict_count = train_realtest[var].value_counts().to_dict()\n",
    "    new_col = var + '_unique'\n",
    "    train_realtest[new_col] = train_realtest[var].apply(lambda s: 0 if dict_count[s]>1 else 1)\n",
    "    #train_realtest[new_col] = train_realtest[var].apply(lambda s: dict_count[s])\n",
    "    #train_realtest[var] = train_realtest[var].apply(lambda s: None if dict_count[s]>1 else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c32c8dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_unique</th>\n",
       "      <th>var_191_unique</th>\n",
       "      <th>var_192_unique</th>\n",
       "      <th>var_193_unique</th>\n",
       "      <th>var_194_unique</th>\n",
       "      <th>var_195_unique</th>\n",
       "      <th>var_196_unique</th>\n",
       "      <th>var_197_unique</th>\n",
       "      <th>var_198_unique</th>\n",
       "      <th>var_199_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>test_199986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2884</td>\n",
       "      <td>-2.8384</td>\n",
       "      <td>11.9149</td>\n",
       "      <td>6.6611</td>\n",
       "      <td>12.3112</td>\n",
       "      <td>12.9244</td>\n",
       "      <td>5.6492</td>\n",
       "      <td>16.0449</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>test_199993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.6764</td>\n",
       "      <td>-8.1066</td>\n",
       "      <td>7.1167</td>\n",
       "      <td>2.4138</td>\n",
       "      <td>10.3845</td>\n",
       "      <td>-11.9327</td>\n",
       "      <td>4.7563</td>\n",
       "      <td>16.0455</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>test_199995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1678</td>\n",
       "      <td>1.0136</td>\n",
       "      <td>10.4333</td>\n",
       "      <td>6.7997</td>\n",
       "      <td>8.5974</td>\n",
       "      <td>-4.1641</td>\n",
       "      <td>4.8579</td>\n",
       "      <td>14.7625</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>test_199996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7171</td>\n",
       "      <td>-9.1462</td>\n",
       "      <td>7.3443</td>\n",
       "      <td>9.1421</td>\n",
       "      <td>12.8936</td>\n",
       "      <td>3.0191</td>\n",
       "      <td>5.6888</td>\n",
       "      <td>18.8862</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>test_199999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.4664</td>\n",
       "      <td>1.8070</td>\n",
       "      <td>10.2277</td>\n",
       "      <td>6.0654</td>\n",
       "      <td>10.0258</td>\n",
       "      <td>1.0789</td>\n",
       "      <td>4.8879</td>\n",
       "      <td>14.4892</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
       "0           train_0     0.0   8.9255 -6.7863  11.9081  5.0930  11.4607   \n",
       "1           train_1     0.0  11.5006 -4.1473  13.8588  5.3890  12.3622   \n",
       "2           train_2     0.0   8.6093 -2.7457  12.0805  7.8928  10.5825   \n",
       "3           train_3     0.0  11.0604 -2.1518   8.9522  7.1957  12.5846   \n",
       "4           train_4     0.0   9.8369 -1.4834  12.8746  6.6375  12.2772   \n",
       "...             ...     ...      ...     ...      ...     ...      ...   \n",
       "199986  test_199986     NaN  19.2884 -2.8384  11.9149  6.6611  12.3112   \n",
       "199993  test_199993     NaN  14.6764 -8.1066   7.1167  2.4138  10.3845   \n",
       "199995  test_199995     NaN  13.1678  1.0136  10.4333  6.7997   8.5974   \n",
       "199996  test_199996     NaN   9.7171 -9.1462   7.3443  9.1421  12.8936   \n",
       "199999  test_199999     NaN  10.4664  1.8070  10.2277  6.0654  10.0258   \n",
       "\n",
       "          var_5   var_6    var_7  ...  var_190_unique  var_191_unique  \\\n",
       "0       -9.2834  5.1187  18.6266  ...               0               0   \n",
       "1        7.0433  5.6208  16.5338  ...               0               0   \n",
       "2       -9.0837  6.9427  14.6155  ...               0               0   \n",
       "3       -1.8361  5.8428  14.9250  ...               0               0   \n",
       "4        2.4486  5.9405  19.2514  ...               0               0   \n",
       "...         ...     ...      ...  ...             ...             ...   \n",
       "199986  12.9244  5.6492  16.0449  ...               0               0   \n",
       "199993 -11.9327  4.7563  16.0455  ...               0               0   \n",
       "199995  -4.1641  4.8579  14.7625  ...               1               0   \n",
       "199996   3.0191  5.6888  18.8862  ...               1               0   \n",
       "199999   1.0789  4.8879  14.4892  ...               0               0   \n",
       "\n",
       "        var_192_unique  var_193_unique  var_194_unique  var_195_unique  \\\n",
       "0                    0               0               0               0   \n",
       "1                    0               0               0               0   \n",
       "2                    0               0               0               0   \n",
       "3                    0               0               0               0   \n",
       "4                    1               1               1               0   \n",
       "...                ...             ...             ...             ...   \n",
       "199986               0               0               0               0   \n",
       "199993               0               0               0               0   \n",
       "199995               0               0               1               0   \n",
       "199996               0               0               0               0   \n",
       "199999               0               0               0               0   \n",
       "\n",
       "        var_196_unique  var_197_unique  var_198_unique  var_199_unique  \n",
       "0                    0               0               0               0  \n",
       "1                    0               0               0               0  \n",
       "2                    0               0               0               0  \n",
       "3                    0               0               0               0  \n",
       "4                    0               0               0               0  \n",
       "...                ...             ...             ...             ...  \n",
       "199986               0               0               0               0  \n",
       "199993               0               0               0               1  \n",
       "199995               0               0               0               1  \n",
       "199996               0               0               0               1  \n",
       "199999               0               0               0               1  \n",
       "\n",
       "[300000 rows x 402 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_realtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c666d",
   "metadata": {},
   "source": [
    "## Split train and real test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772e3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = train_realtest[train_realtest['ID_code'].str.contains('train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00401421",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new = train_realtest[train_realtest['ID_code'].str.contains('test')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa2c89c",
   "metadata": {},
   "source": [
    "## Build 200 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a386a4",
   "metadata": {},
   "source": [
    "* each time use one original feature and corresponding frequency feature to build a model\n",
    "* then use logit transfer the prediction of probability got from one model and sum up these result from 200 models\n",
    "* then get mean of these result from 200 models and use exp to transfer into probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e8c9d",
   "metadata": {},
   "source": [
    "* Actually I'm not sure why they use logit here, but I just follow that. And to get probability instead of large negative number, I used exp to transfer and the score looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "129a1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit, expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d541174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = train_new.drop(columns=['ID_code', 'target'])\n",
    "y_train_all = train_new['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da196a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_test = df_test.drop(columns=['ID_code','has_unique'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34670325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = [x for x in X_train.columns if x.startswith(\"var\")]\n",
    "features = X_train_all.columns[0:200].to_list()\n",
    "\n",
    "pred = 0\n",
    "for var in features:\n",
    "    model = lgb.LGBMClassifier(**{'learning_rate': 0.05, \n",
    "                                  'max_bin': 165, \n",
    "                                  'max_depth': 5, \n",
    "                                  'min_child_samples': 150,\n",
    "                                  'min_child_weight': 0.1, \n",
    "                                  'min_split_gain': 0.0018, \n",
    "                                  'n_estimators': 41,\n",
    "                                  'num_leaves': 6, \n",
    "                                  'reg_alpha': 2.0, \n",
    "                                  'reg_lambda': 2.54, \n",
    "                                  'objective': 'binary', \n",
    "                                  'n_jobs': -1})\n",
    "    var_count_name = var + '_unique'\n",
    "    model = model.fit(np.hstack([X_train_all[var].values.reshape(-1, 1),\n",
    "                      X_train_all[var_count_name].values.reshape(-1, 1)]), y_train_all.values)\n",
    "    pred += logit(model.predict_proba(np.hstack([X_df_test[var].values.reshape(-1, 1),\n",
    "                  X_df_test[var_count_name].values.reshape(-1, 1)]))[:, 1])\n",
    "    \n",
    "#pd.DataFrame({\"ID_code\": test_id, \"target\": pred}).to_csv(\"submission3.csv\", index = False)\n",
    "b = pd.DataFrame({\"ID_code\": df_test['ID_code'], \"target\": pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0285383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b['target'] = np.exp(b['target']/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to_csv(\"submission8.csv\", index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.884: submission4 -- adding frequency \n",
    "#0.887: submission8 -- adding frequency and change frequency>1 into 0\n",
    "#0.85: submission5 -- adding frequency and change unique frequency into None\n",
    "#0.87 submission6 -- adding frequency and change non-unique frequency into None\n",
    "#0.77 submission7 -- change original variable nonunique into Nonea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915d3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e9e595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
